{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7746b00f-5b5a-4866-831d-12b56c715dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f68a27f-889d-4c30-830e-1e1c54a38a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep(x):\n",
    "    time.sleep(x)\n",
    "    \n",
    "def wait(x):\n",
    "    driver.implicitly_wait(x)\n",
    "    \n",
    "def click_bann_byID(ID):\n",
    "    actions = ActionChains(driver)\n",
    "    akzeptieren = driver.find_element(By.ID, ID)\n",
    "    actions.click(akzeptieren).perform()\n",
    "    wait(10)\n",
    "    sleep(0.5)\n",
    "\n",
    "def find_elements_HPCO(H,P,C,O):\n",
    "    if website_name == 'jobware':\n",
    "        header = driver.find_elements(By.TAG_NAME, H)\n",
    "    else:\n",
    "        header = driver.find_elements(By.CLASS_NAME, H)\n",
    "    publish = driver.find_elements(By.CLASS_NAME, P)\n",
    "    company = driver.find_elements(By.CLASS_NAME, C)\n",
    "    ort = driver.find_elements(By.CLASS_NAME, O) \n",
    "\n",
    "    list_header = [title.text for title in header]\n",
    "    list_publish = [pub.text for pub in publish]\n",
    "    list_company = [comp.text for comp in company]\n",
    "    list_ort = [o.text for o in ort]\n",
    "    return list_header, list_publish, list_company, list_ort\n",
    "\n",
    "\n",
    "def scroll_down(x):\n",
    "    n=0\n",
    "    while n < x:\n",
    "        n+=1\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        sleep(1.5)\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        sleep(1.5)\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        sleep(1.5)\n",
    "        actions.key_down(Keys.PAGE_UP).perform()\n",
    "        sleep(0.10)\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        wait(10)\n",
    "        sleep(2.5)\n",
    "\n",
    "\n",
    "def scroll_down_first(x):\n",
    "    n=0\n",
    "    while n < x:\n",
    "        n+=1\n",
    "        driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight)\", \"\")\n",
    "        wait(10)\n",
    "        sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f24bb0e-db35-4c09-950f-541b8871c539",
   "metadata": {},
   "source": [
    "# 01 - STEPSTONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "962f38df-d454-44d7-afcc-8b1e7917ae67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- StepStone Job Searching Selenium Project ----------------------\n",
      "Header 25 Publish 25 Company 25 Ort 25 Desc 25 Link 25\n",
      "Number of Jobs Pages = 21\n",
      "Page Number : 2, DataFrame Shape : (25, 6)\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=107.0.5304.110)\nStacktrace:\n0   chromedriver                        0x00000001064e62c8 chromedriver + 4752072\n1   chromedriver                        0x0000000106466463 chromedriver + 4228195\n2   chromedriver                        0x00000001060c9b18 chromedriver + 441112\n3   chromedriver                        0x00000001060a6210 chromedriver + 295440\n4   chromedriver                        0x000000010612be3d chromedriver + 843325\n5   chromedriver                        0x000000010613f719 chromedriver + 923417\n6   chromedriver                        0x0000000106127b33 chromedriver + 826163\n7   chromedriver                        0x00000001060f89fd chromedriver + 633341\n8   chromedriver                        0x00000001060fa051 chromedriver + 639057\n9   chromedriver                        0x00000001064b330e chromedriver + 4543246\n10  chromedriver                        0x00000001064b7a88 chromedriver + 4561544\n11  chromedriver                        0x00000001064bf6df chromedriver + 4593375\n12  chromedriver                        0x00000001064b88fa chromedriver + 4565242\n13  chromedriver                        0x000000010648e2cf chromedriver + 4391631\n14  chromedriver                        0x00000001064d75b8 chromedriver + 4691384\n15  chromedriver                        0x00000001064d7739 chromedriver + 4691769\n16  chromedriver                        0x00000001064ed81e chromedriver + 4782110\n17  libsystem_pthread.dylib             0x00007fff20521950 _pthread_start + 224\n18  libsystem_pthread.dylib             0x00007fff2051d47b thread_start + 15\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 75>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m sleep(\u001b[38;5;241m1.5\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# 4.2 - Find the elements and get the Texts\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m list_header, list_publish, list_company, list_ort \u001b[38;5;241m=\u001b[39m \u001b[43mfind_elements_HPCO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43mO\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     86\u001b[0m description \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mCLASS_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresultlist-1pq4x2u\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     87\u001b[0m list_description \u001b[38;5;241m=\u001b[39m [des\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m des \u001b[38;5;129;01min\u001b[39;00m description]\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mfind_elements_HPCO\u001b[0;34m(H, P, C, O)\u001b[0m\n\u001b[1;32m     16\u001b[0m     header \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mTAG_NAME, H)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m     header \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLASS_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m publish \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mCLASS_NAME, P)\n\u001b[1;32m     20\u001b[0m company \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mCLASS_NAME, C)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:889\u001b[0m, in \u001b[0;36mWebDriver.find_elements\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    885\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m value\n\u001b[1;32m    887\u001b[0m \u001b[38;5;66;03m# Return empty list if driver returns null\u001b[39;00m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;66;03m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m []\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:429\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[1;32m    431\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/errorhandler.py:243\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    241\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=107.0.5304.110)\nStacktrace:\n0   chromedriver                        0x00000001064e62c8 chromedriver + 4752072\n1   chromedriver                        0x0000000106466463 chromedriver + 4228195\n2   chromedriver                        0x00000001060c9b18 chromedriver + 441112\n3   chromedriver                        0x00000001060a6210 chromedriver + 295440\n4   chromedriver                        0x000000010612be3d chromedriver + 843325\n5   chromedriver                        0x000000010613f719 chromedriver + 923417\n6   chromedriver                        0x0000000106127b33 chromedriver + 826163\n7   chromedriver                        0x00000001060f89fd chromedriver + 633341\n8   chromedriver                        0x00000001060fa051 chromedriver + 639057\n9   chromedriver                        0x00000001064b330e chromedriver + 4543246\n10  chromedriver                        0x00000001064b7a88 chromedriver + 4561544\n11  chromedriver                        0x00000001064bf6df chromedriver + 4593375\n12  chromedriver                        0x00000001064b88fa chromedriver + 4565242\n13  chromedriver                        0x000000010648e2cf chromedriver + 4391631\n14  chromedriver                        0x00000001064d75b8 chromedriver + 4691384\n15  chromedriver                        0x00000001064d7739 chromedriver + 4691769\n16  chromedriver                        0x00000001064ed81e chromedriver + 4782110\n17  libsystem_pthread.dylib             0x00007fff20521950 _pthread_start + 224\n18  libsystem_pthread.dylib             0x00007fff2051d47b thread_start + 15\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Title : Web Scrapping by Selenium \n",
    "Project Purpose: From StepStone scrap data for some Job Titels\n",
    "1 - Create Driver\n",
    "2 - Go to Website\n",
    "3 - Create ActionChain Object\n",
    "    3.1 - Click Banned Accept\n",
    "4 - Take Title and Infos from Page\n",
    "    4.1 - Create Lists \n",
    "    4.2 - Create DataFrame\n",
    "    4.3 - Repeat Process\n",
    "    4.4 - Print and Save DataFrame\n",
    "'''\n",
    "\n",
    "print('---------------------- StepStone Job Searching Selenium Project ----------------------')\n",
    "start=datetime.now()  \n",
    "# 0 Link Descriptions\n",
    "link_original_stepstone = 'https://www.stepstone.de/jobs/data-analyst/in-rietberg?radius=50&page=2'\n",
    "\n",
    "website_name = 'stepstone'\n",
    "job_name = 'Data Analyst'\n",
    "#job_name = 'Business Analyst'\n",
    "ort_ = 'Rietberg'\n",
    "radius = 50\n",
    "page_number = 1\n",
    "\n",
    "#  1 - Create Driver\n",
    "Path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/chromedriver'\n",
    "driver = webdriver.Chrome(Path)\n",
    "\n",
    "#  2 - Go to Website\n",
    "job_link = job_name.replace(' ', '-').lower()\n",
    "ort_link = ort_.lower()\n",
    "link = f'https://www.stepstone.de/jobs/{job_link}/in-{ort_link}?radius={radius}&page={page_number}'\n",
    "\n",
    "driver.get(link)\n",
    "wait(10)\n",
    "sleep(2)\n",
    "\n",
    "#  3 - ActionChain Object created\n",
    "# 3.1 - Click Banned Accept\n",
    "ID = 'ccmgt_explicit_accept'\n",
    "click_bann_byID(ID)\n",
    "\n",
    "# 4 -  Take Infos from Page\n",
    "# Headers, Publish_Time ,Company, City\n",
    "H, P, C, O = 'resultlist-12iu5pk', 'resultlist-3asi6i', 'resultlist-1v262t5', 'resultlist-dettfq'\n",
    "list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O)\n",
    "\n",
    "# Description and Page number of results\n",
    "description = driver.find_elements(By.CLASS_NAME, 'resultlist-1pq4x2u')\n",
    "result = driver.find_elements(By.CLASS_NAME, 'resultlist-xeyevn')\n",
    "\n",
    "\n",
    "# Get Links\n",
    "header = driver.find_elements(By.CLASS_NAME, H)\n",
    "list_link = [link.get_attribute('href') for link in header]\n",
    "\n",
    "# 4.1 - Get Texts for each finding\n",
    "list_description = [des.text for des in description]\n",
    "print('Header',len(list_header), 'Publish',len(list_publish), 'Company',len(list_company), 'Ort',len(list_ort), 'Desc', len(list_description), 'Link',len(list_link))\n",
    "\n",
    "# Total Search Page Number\n",
    "list_result = [res.text for res in result]\n",
    "number_of_page = int(list_result[0].split(' ')[-1])\n",
    "print(f'Number of Jobs Pages = {number_of_page}')\n",
    "\n",
    "# 4.2 - DataFrame df\n",
    "d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company=np.array(list_company), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "df = pd.DataFrame.from_dict(d, orient='index')\n",
    "df = df.T\n",
    "\n",
    "\n",
    "# 4.3 Repeat Process for every Web Page\n",
    "while  page_number < number_of_page:\n",
    "    page_number+=1\n",
    "    \n",
    "    # 4.1 - Go to another page\n",
    "    link = f'https://www.stepstone.de/jobs/{job_link}/in-{ort_link}?radius={radius}&page={page_number}'\n",
    "    driver.get(link)\n",
    "    wait(10)\n",
    "    sleep(1.5)\n",
    "    \n",
    "    # 4.2 - Find the elements and get the Texts\n",
    "    list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O) \n",
    "    description = driver.find_elements(By.CLASS_NAME, 'resultlist-1pq4x2u')\n",
    "    list_description = [des.text for des in description]\n",
    "    header = driver.find_elements(By.CLASS_NAME, H)\n",
    "    list_link = [link.get_attribute('href') for link in header]\n",
    " \n",
    "    # 4.3 - Create new page Dataframe\n",
    "    d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company=np.array(list_company), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "    df2 = pd.DataFrame.from_dict(d, orient='index')\n",
    "    df2 = df2.T\n",
    "    \n",
    "    # 4.4 - Concatenate the DataFrames\n",
    "    df = pd.concat([df,df2], axis=0, ignore_index=True)\n",
    "    print(f'Page Number : {page_number}, DataFrame Shape : {df2.shape}')\n",
    "    \n",
    "\n",
    "# 4.4 Save Data as csv \n",
    "print(f'DataFrame End : {df.shape}')\n",
    "df['website'] = website_name\n",
    "# 4.3 - Save DataFrame\n",
    "# 4.3.1 - to csv\n",
    "path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/data'\n",
    "job_name2 = job_name.replace(' ', '-')\n",
    "time_ = datetime.today().strftime('%Y-%m-%d')\n",
    "df.to_csv(f'{path}/{job_name2}-{time_}.csv', index=False)\n",
    "\n",
    "end =datetime.now() \n",
    "print('Code Runned No Problem')\n",
    "print(f'Time = {end - start}')\n",
    "sleep(5)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bba6fe-9b6e-4110-8eb6-2c9444a77965",
   "metadata": {},
   "source": [
    "# 02 - JOBWARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74123825-811b-4b9e-b02f-1d35ac17737b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('---------------------- Jobware Job Searching Selenium Project ----------------------')\n",
    "\n",
    "start=datetime.now()  \n",
    "# 0 Link Descriptions\n",
    "link_original = 'https://www.jobware.de/jobsuche?jw_jobname=data%20analyst&jw_jobort=333**%20Rietberg&jw_ort_distance=50'\n",
    "\n",
    "website_name = 'jobware'\n",
    "radius = 50\n",
    "page_number = 0\n",
    "\n",
    "#  1 - Create Driver\n",
    "Path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/chromedriver'\n",
    "driver = webdriver.Chrome(Path)\n",
    "\n",
    "#  2 - Go to Website\n",
    "job_link = job_name.replace(' ', '%20').lower()\n",
    "ort_link = ort_.capitalize()\n",
    "link = f'https://www.jobware.de/jobsuche?jw_jobname={job_link}&jw_jobort=333**%20{ort_}&jw_ort_distance={radius}'\n",
    "\n",
    "driver.get(link)\n",
    "wait(10)\n",
    "sleep(2)\n",
    "\n",
    "#  3 - ActionChain Object created\n",
    "# 3.1 - Click Banned Accept\n",
    "actions = ActionChains(driver)\n",
    "akzeptieren = driver.find_element(By.XPATH, '/html/body/div[1]/div/div[3]/div[2]/button')\n",
    "actions.click(akzeptieren).perform()\n",
    "wait(10)\n",
    "sleep(0.5)\n",
    "#dsgvo-1B76C4DA4B-orange dsgvo-1B76C4DA4B-accept\n",
    "\n",
    "# 4 -  Take Infos from Page\n",
    "# Headers, Company, City, Description\n",
    "H, P, C, O = 'h2', 'date', 'company', 'location'\n",
    "list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O)\n",
    "description = driver.find_elements(By.CLASS_NAME, 'task')\n",
    "list_description = [des.text for des in description]\n",
    "\n",
    "links = driver.find_elements(By.CLASS_NAME, 'job')\n",
    "list_link = [link.get_attribute('href') for link in links]\n",
    "\n",
    "print('Header',len(list_header), 'Publish',len(list_publish), 'Company',len(list_company), 'Ort',len(list_ort), 'Desc', len(list_description), 'Link',len(list_link))\n",
    "\n",
    "# Total Search Page Number\n",
    "result = driver.find_elements(By.CLASS_NAME, 'result-sort')\n",
    "list_result = [res.text for res in result]\n",
    "print(list_result)\n",
    "\n",
    "# 4.2 - DataFrame df\n",
    "d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company=np.array(list_company), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "df = pd.DataFrame.from_dict(d, orient='index')\n",
    "df = df.T\n",
    "\n",
    "# 4.4 Save Data as csv and xlsx    \n",
    "print(f'DataFrame End : {df.shape}')\n",
    "df['website'] = website_name\n",
    "# 4.3 - Save DataFrame\n",
    "# 4.3.1 - to csv\n",
    "df.to_csv(f'{path}/{job_name2}-{time_}.csv', mode='a', index=False, header=False)\n",
    "\n",
    "end =datetime.now() \n",
    "print('Code Runned No Problem')\n",
    "print(f'Time = {end - start}')\n",
    "sleep(5)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abde48a-5765-4f02-81fd-b32ce46555e1",
   "metadata": {},
   "source": [
    "# 03 - LINKEDIN (Chrome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbf2fbe-1a18-43d0-b510-6c6015993c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('---------------------- Linkedin Job Searching Selenium Project ----------------------')\n",
    "   \n",
    "\n",
    "start=datetime.now()  \n",
    "# 0 Link Descriptions\n",
    "link_original = 'https://www.linkedin.com/jobs/search/?currentJobId=3199974140&distance=25&keywords=data%20analyst&location=Rietberg' \n",
    "\n",
    "website_name =  'linkedin'\n",
    "radius = 40\n",
    "page_number = 1\n",
    "\n",
    "#  1 - Create Driver\n",
    "Path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/chromedriver'\n",
    "driver = webdriver.Chrome(Path)\n",
    "\n",
    "#  2 - Go to Website\n",
    "job_link = job_name.replace(' ', '%20').lower()\n",
    "\n",
    "link2 = f'https://www.linkedin.com/jobs/search/?distance=25&keywords={job_link}&location={ort_}'\n",
    "driver.get(link2)\n",
    "wait(10)\n",
    "sleep(2)\n",
    "\n",
    "\n",
    "#  3 - ActionChain Object created\n",
    "# 3.1 - Click Banned Accept\n",
    "actions = ActionChains(driver)\n",
    "akzeptieren = driver.find_element(By.TAG_NAME, 'button')\n",
    "actions.click(akzeptieren).perform()\n",
    "wait(10)\n",
    "sleep(0.5)\n",
    "\n",
    "# 3.1 - \n",
    "scroller = driver.find_element(By.CLASS_NAME, 'infinite-scroller__show-more-button')\n",
    "\n",
    "scroll_down(4)\n",
    "\n",
    "# 4 -  Take Infos from Page\n",
    "# Headers, Company, City, Description\n",
    "H, P, C, O = 'base-search-card__title', 'job-search-card__listdate', 'hidden-nested-link', 'job-search-card__location'\n",
    "list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O)\n",
    "\n",
    "#description = driver.find_elements(By.CLASS_NAME, 'resultlist-1pq4x2u')\n",
    "result = driver.find_elements(By.CLASS_NAME, 'results-context-header__context')\n",
    "\n",
    "\n",
    "# Link Lists\n",
    "links = driver.find_elements(By.CLASS_NAME, 'base-card__full-link')\n",
    "list_link = [link.get_attribute('href') for link in links]\n",
    "\n",
    "print('Header',len(list_header), 'Publish',len(list_publish), 'Company',len(list_company), 'Ort',len(list_ort), 'Desc', len(list_description), 'Link',len(list_link))\n",
    "\n",
    "# Total Search Page Number\n",
    "list_result = [res.text for res in result]\n",
    "print(f'Number of Jobs Pages = {list_result}')\n",
    "\n",
    "\n",
    "# 4.2 - DataFrame df\n",
    "d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company=np.array(list_company), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "df = pd.DataFrame.from_dict(d, orient='index')\n",
    "df = df.T\n",
    "df['description'] = None\n",
    "df['website'] = website_name\n",
    "\n",
    "# 4.4 Save Data as csv and xlsx    \n",
    "print(f'DataFrame End : {df.shape}')\n",
    "# 4.3 - Save DataFrame\n",
    "# 4.3.1 - to csv\n",
    "df.loc[df.website =='linkedin', 'city'] = df.loc[df.website =='linkedin', 'city'].str.replace(', Kuzey Ren-Vestfalya, Almanya', '')\n",
    "df.to_csv(f'{path}/{job_name2}-{time_}.csv', mode='a', index=False, header=False)\n",
    "\n",
    "# 4.3.2 - to excel\n",
    "# install openpyxl\n",
    "#df.to_excel(f'{path}/{job_name2}-{time_}.xlsx', sheet_name='Sheet3')\n",
    "\n",
    "end =datetime.now() \n",
    "print('Code Runned No Problem')\n",
    "print(f'Time = {end - start}')\n",
    "sleep(5)\n",
    "driver.quit()\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
