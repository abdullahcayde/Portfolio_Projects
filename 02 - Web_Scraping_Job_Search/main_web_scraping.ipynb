{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7746b00f-5b5a-4866-831d-12b56c715dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f68a27f-889d-4c30-830e-1e1c54a38a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep(x):\n",
    "    time.sleep(x)\n",
    "    \n",
    "def wait(x):\n",
    "    driver.implicitly_wait(x)\n",
    "    \n",
    "def click_bann_byID(ID):\n",
    "    actions = ActionChains(driver)\n",
    "    akzeptieren = driver.find_element(By.ID, ID)\n",
    "    actions.click(akzeptieren).perform()\n",
    "    wait(10)\n",
    "    sleep(0.5)\n",
    "\n",
    "def find_elements_HPCO(H,P,C,O):\n",
    "    if website_name == 'jobware':\n",
    "        header = driver.find_elements(By.TAG_NAME, H)\n",
    "    else:\n",
    "        header = driver.find_elements(By.CLASS_NAME, H)\n",
    "    publish = driver.find_elements(By.CLASS_NAME, P)\n",
    "    company = driver.find_elements(By.CLASS_NAME, C)\n",
    "    ort = driver.find_elements(By.CLASS_NAME, O) \n",
    "\n",
    "    list_header = [title.text for title in header]\n",
    "    list_publish = [pub.text for pub in publish]\n",
    "    list_company = [comp.text for comp in company]\n",
    "    list_ort = [o.text for o in ort]\n",
    "    return list_header, list_publish, list_company, list_ort\n",
    "\n",
    "\n",
    "def scroll_down(x):\n",
    "    n=0\n",
    "    while n < x:\n",
    "        n+=1\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        sleep(1.5)\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        sleep(1.5)\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        sleep(1.5)\n",
    "        actions.key_down(Keys.PAGE_UP).perform()\n",
    "        sleep(0.10)\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        wait(10)\n",
    "        sleep(2.5)\n",
    "\n",
    "\n",
    "def scroll_down_first(x):\n",
    "    n=0\n",
    "    while n < x:\n",
    "        n+=1\n",
    "        driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight)\", \"\")\n",
    "        wait(10)\n",
    "        sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f24bb0e-db35-4c09-950f-541b8871c539",
   "metadata": {},
   "source": [
    "# 01 - STEPSTONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "962f38df-d454-44d7-afcc-8b1e7917ae67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- StepStone Job Searching Selenium Project ----------------------\n",
      "Header 25 Publish 25 Company 25 Ort 25 Desc 25 Link 25\n",
      "Number of Jobs Pages = 3\n",
      "Page Number : 2, DataFrame Shape : (25, 6)\n",
      "Page Number : 3, DataFrame Shape : (7, 6)\n",
      "DataFrame End : (57, 6)\n",
      "Code Runned No Problem\n",
      "Time = 0:00:48.477025\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Title : Web Scrapping by Selenium \n",
    "Project Purpose: From StepStone scrap data for some Job Titels\n",
    "1 - Create Driver\n",
    "2 - Go to Website\n",
    "3 - Create ActionChain Object\n",
    "    3.1 - Click Banned Accept\n",
    "4 - Take Title and Infos from Page\n",
    "    4.1 - Create Lists \n",
    "    4.2 - Create DataFrame\n",
    "    4.3 - Repeat Process\n",
    "    4.4 - Print and Save DataFrame\n",
    "'''\n",
    "\n",
    "print('---------------------- StepStone Job Searching Selenium Project ----------------------')\n",
    "start=datetime.now()  \n",
    "# 0 Link Descriptions\n",
    "link_original_stepstone = 'https://www.stepstone.de/jobs/data-analyst/in-rietberg?radius=50&page=2'\n",
    "\n",
    "website_name = 'stepstone'\n",
    "job_name = 'Business Analyst'\n",
    "ort_ = 'Rietberg'\n",
    "radius = 50\n",
    "page_number = 1\n",
    "\n",
    "#  1 - Create Driver\n",
    "Path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/chromedriver'\n",
    "driver = webdriver.Chrome(Path)\n",
    "\n",
    "#  2 - Go to Website\n",
    "job_link = job_name.replace(' ', '-').lower()\n",
    "ort_link = ort_.lower()\n",
    "link = f'https://www.stepstone.de/jobs/{job_link}/in-{ort_link}?radius={radius}&page={page_number}'\n",
    "\n",
    "driver.get(link)\n",
    "wait(10)\n",
    "sleep(2)\n",
    "\n",
    "#  3 - ActionChain Object created\n",
    "# 3.1 - Click Banned Accept\n",
    "ID = 'ccmgt_explicit_accept'\n",
    "click_bann_byID(ID)\n",
    "\n",
    "# 4 -  Take Infos from Page\n",
    "# Headers, Publish_Time ,Company, City\n",
    "H, P, C, O = 'resultlist-12iu5pk', 'resultlist-3asi6i', 'resultlist-1v262t5', 'resultlist-dettfq'\n",
    "list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O)\n",
    "\n",
    "# Description and Page number of results\n",
    "description = driver.find_elements(By.CLASS_NAME, 'resultlist-1pq4x2u')\n",
    "result = driver.find_elements(By.CLASS_NAME, 'resultlist-xeyevn')\n",
    "\n",
    "\n",
    "# Get Links\n",
    "header = driver.find_elements(By.CLASS_NAME, H)\n",
    "list_link = [link.get_attribute('href') for link in header]\n",
    "\n",
    "# 4.1 - Get Texts for each finding\n",
    "list_description = [des.text for des in description]\n",
    "print('Header',len(list_header), 'Publish',len(list_publish), 'Company',len(list_company), 'Ort',len(list_ort), 'Desc', len(list_description), 'Link',len(list_link))\n",
    "\n",
    "# Total Search Page Number\n",
    "list_result = [res.text for res in result]\n",
    "number_of_page = int(list_result[0].split(' ')[-1])\n",
    "print(f'Number of Jobs Pages = {number_of_page}')\n",
    "\n",
    "# 4.2 - DataFrame df\n",
    "d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company=np.array(list_company), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "df = pd.DataFrame.from_dict(d, orient='index')\n",
    "df = df.T\n",
    "\n",
    "\n",
    "# 4.3 Repeat Process for every Web Page\n",
    "while  page_number < number_of_page:\n",
    "    page_number+=1\n",
    "    \n",
    "    # 4.1 - Go to another page\n",
    "    link = f'https://www.stepstone.de/jobs/{job_link}/in-{ort_link}?radius={radius}&page={page_number}'\n",
    "    driver.get(link)\n",
    "    wait(10)\n",
    "    sleep(1.5)\n",
    "    \n",
    "    # 4.2 - Find the elements and get the Texts\n",
    "    list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O) \n",
    "    description = driver.find_elements(By.CLASS_NAME, 'resultlist-1pq4x2u')\n",
    "    list_description = [des.text for des in description]\n",
    "    header = driver.find_elements(By.CLASS_NAME, H)\n",
    "    list_link = [link.get_attribute('href') for link in header]\n",
    " \n",
    "    # 4.3 - Create new page Dataframe\n",
    "    d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company=np.array(list_company), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "    df2 = pd.DataFrame.from_dict(d, orient='index')\n",
    "    df2 = df2.T\n",
    "    \n",
    "    # 4.4 - Concatenate the DataFrames\n",
    "    df = pd.concat([df,df2], axis=0, ignore_index=True)\n",
    "    print(f'Page Number : {page_number}, DataFrame Shape : {df2.shape}')\n",
    "    \n",
    "\n",
    "# 4.4 Save Data as csv \n",
    "print(f'DataFrame End : {df.shape}')\n",
    "df['website'] = website_name\n",
    "# 4.3 - Save DataFrame\n",
    "# 4.3.1 - to csv\n",
    "path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/data'\n",
    "job_name2 = job_name.replace(' ', '-')\n",
    "time_ = datetime.today().strftime('%Y-%m-%d')\n",
    "df.to_csv(f'{path}/{job_name2}-{time_}.csv', index=False)\n",
    "\n",
    "end =datetime.now() \n",
    "print('Code Runned No Problem')\n",
    "print(f'Time = {end - start}')\n",
    "sleep(5)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bba6fe-9b6e-4110-8eb6-2c9444a77965",
   "metadata": {},
   "source": [
    "# 02 - JOBWARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74123825-811b-4b9e-b02f-1d35ac17737b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- Jobware Job Searching Selenium Project ----------------------\n",
      "Header 12 Publish 12 Company 12 Ort 12 Desc 12 Link 12\n",
      "['12 Treffer\\nSortierung: Relevanz - Datum']\n",
      "DataFrame End : (12, 6)\n",
      "Code Runned No Problem\n",
      "Time = 0:00:28.200556\n"
     ]
    }
   ],
   "source": [
    "print('---------------------- Jobware Job Searching Selenium Project ----------------------')\n",
    "\n",
    "start=datetime.now()  \n",
    "# 0 Link Descriptions\n",
    "link_original = 'https://www.jobware.de/jobsuche?jw_jobname=data%20analyst&jw_jobort=333**%20Rietberg&jw_ort_distance=50'\n",
    "\n",
    "website_name = 'jobware'\n",
    "radius = 50\n",
    "page_number = 0\n",
    "\n",
    "#  1 - Create Driver\n",
    "Path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/chromedriver'\n",
    "driver = webdriver.Chrome(Path)\n",
    "\n",
    "#  2 - Go to Website\n",
    "job_link = job_name.replace(' ', '%20').lower()\n",
    "ort_link = ort_.capitalize()\n",
    "link = f'https://www.jobware.de/jobsuche?jw_jobname={job_link}&jw_jobort=333**%20{ort_}&jw_ort_distance={radius}'\n",
    "\n",
    "driver.get(link)\n",
    "wait(10)\n",
    "sleep(2)\n",
    "\n",
    "#  3 - ActionChain Object created\n",
    "# 3.1 - Click Banned Accept\n",
    "actions = ActionChains(driver)\n",
    "akzeptieren = driver.find_element(By.XPATH, '/html/body/div[1]/div/div[3]/div[2]/button')\n",
    "actions.click(akzeptieren).perform()\n",
    "wait(10)\n",
    "sleep(0.5)\n",
    "#dsgvo-1B76C4DA4B-orange dsgvo-1B76C4DA4B-accept\n",
    "\n",
    "# 4 -  Take Infos from Page\n",
    "# Headers, Company, City, Description\n",
    "H, P, C, O = 'h2', 'date', 'company', 'location'\n",
    "list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O)\n",
    "description = driver.find_elements(By.CLASS_NAME, 'task')\n",
    "list_description = [des.text for des in description]\n",
    "\n",
    "links = driver.find_elements(By.CLASS_NAME, 'job')\n",
    "list_link = [link.get_attribute('href') for link in links]\n",
    "\n",
    "print('Header',len(list_header), 'Publish',len(list_publish), 'Company',len(list_company), 'Ort',len(list_ort), 'Desc', len(list_description), 'Link',len(list_link))\n",
    "\n",
    "# Total Search Page Number\n",
    "result = driver.find_elements(By.CLASS_NAME, 'result-sort')\n",
    "list_result = [res.text for res in result]\n",
    "print(list_result)\n",
    "\n",
    "# 4.2 - DataFrame df\n",
    "d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company=np.array(list_company), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "df = pd.DataFrame.from_dict(d, orient='index')\n",
    "df = df.T\n",
    "\n",
    "# 4.4 Save Data as csv and xlsx    \n",
    "print(f'DataFrame End : {df.shape}')\n",
    "df['website'] = website_name\n",
    "# 4.3 - Save DataFrame\n",
    "# 4.3.1 - to csv\n",
    "df.to_csv(f'{path}/{job_name2}-{time_}.csv', mode='a', index=False, header=False)\n",
    "\n",
    "end =datetime.now() \n",
    "print('Code Runned No Problem')\n",
    "print(f'Time = {end - start}')\n",
    "sleep(5)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abde48a-5765-4f02-81fd-b32ce46555e1",
   "metadata": {},
   "source": [
    "# 03 - LINKEDIN (Chrome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dbf2fbe-1a18-43d0-b510-6c6015993c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- Linkedin Job Searching Selenium Project ----------------------\n",
      "Header 34 Publish 32 Company 32 Ort 34 Desc 12 Link 32\n",
      "Number of Jobs Pages = ['Rietberg, Kuzey Ren-Vestfalya, Almanya konumunda 34 Business Analyst iş ilanı (2 yeni)']\n",
      "DataFrame End : (34, 7)\n",
      "Code Runned No Problem\n",
      "Time = 0:00:41.163029\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>publish</th>\n",
       "      <th>company</th>\n",
       "      <th>city</th>\n",
       "      <th>description</th>\n",
       "      <th>link</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Analyst (M/W/D)</td>\n",
       "      <td>1 hafta önce</td>\n",
       "      <td>Positive Thinking Company</td>\n",
       "      <td>Bielefeld</td>\n",
       "      <td>None</td>\n",
       "      <td>https://de.linkedin.com/jobs/view/business-ana...</td>\n",
       "      <td>linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Business Analyst (w/m/d) Marketplace</td>\n",
       "      <td>2 hafta önce</td>\n",
       "      <td>Kaufland e-commerce</td>\n",
       "      <td>Langenberg</td>\n",
       "      <td>None</td>\n",
       "      <td>https://de.linkedin.com/jobs/view/junior-busin...</td>\n",
       "      <td>linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data / Business Analyst (m/w/d)</td>\n",
       "      <td>3 hafta önce</td>\n",
       "      <td>Dr. Wolff Group</td>\n",
       "      <td>Bielefeld</td>\n",
       "      <td>None</td>\n",
       "      <td>https://de.linkedin.com/jobs/view/data-busines...</td>\n",
       "      <td>linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Business Analyst - Customer Experience ...</td>\n",
       "      <td>3 hafta önce</td>\n",
       "      <td>NEOMATIC AG</td>\n",
       "      <td>Bielefeld</td>\n",
       "      <td>None</td>\n",
       "      <td>https://de.linkedin.com/jobs/view/senior-busin...</td>\n",
       "      <td>linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Solution Analyst (m/f/d)</td>\n",
       "      <td>1 ay önce</td>\n",
       "      <td>Infopulse</td>\n",
       "      <td>Bielefeld</td>\n",
       "      <td>None</td>\n",
       "      <td>https://de.linkedin.com/jobs/view/business-sol...</td>\n",
       "      <td>linkedin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title       publish  \\\n",
       "0                           Business Analyst (M/W/D)  1 hafta önce   \n",
       "1        Junior Business Analyst (w/m/d) Marketplace  2 hafta önce   \n",
       "2                    Data / Business Analyst (m/w/d)  3 hafta önce   \n",
       "3  Senior Business Analyst - Customer Experience ...  3 hafta önce   \n",
       "4                  Business Solution Analyst (m/f/d)     1 ay önce   \n",
       "\n",
       "                     company        city description  \\\n",
       "0  Positive Thinking Company   Bielefeld        None   \n",
       "1        Kaufland e-commerce  Langenberg        None   \n",
       "2            Dr. Wolff Group   Bielefeld        None   \n",
       "3                NEOMATIC AG   Bielefeld        None   \n",
       "4                  Infopulse   Bielefeld        None   \n",
       "\n",
       "                                                link   website  \n",
       "0  https://de.linkedin.com/jobs/view/business-ana...  linkedin  \n",
       "1  https://de.linkedin.com/jobs/view/junior-busin...  linkedin  \n",
       "2  https://de.linkedin.com/jobs/view/data-busines...  linkedin  \n",
       "3  https://de.linkedin.com/jobs/view/senior-busin...  linkedin  \n",
       "4  https://de.linkedin.com/jobs/view/business-sol...  linkedin  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('---------------------- Linkedin Job Searching Selenium Project ----------------------')\n",
    "   \n",
    "\n",
    "start=datetime.now()  \n",
    "# 0 Link Descriptions\n",
    "link_original = 'https://www.linkedin.com/jobs/search/?currentJobId=3199974140&distance=25&keywords=data%20analyst&location=Rietberg' \n",
    "\n",
    "website_name =  'linkedin'\n",
    "radius = 40\n",
    "page_number = 1\n",
    "\n",
    "#  1 - Create Driver\n",
    "Path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/chromedriver'\n",
    "driver = webdriver.Chrome(Path)\n",
    "\n",
    "#  2 - Go to Website\n",
    "job_link = job_name.replace(' ', '%20').lower()\n",
    "\n",
    "link2 = f'https://www.linkedin.com/jobs/search/?distance=25&keywords={job_link}&location={ort_}'\n",
    "driver.get(link2)\n",
    "wait(10)\n",
    "sleep(2)\n",
    "\n",
    "\n",
    "#  3 - ActionChain Object created\n",
    "# 3.1 - Click Banned Accept\n",
    "actions = ActionChains(driver)\n",
    "akzeptieren = driver.find_element(By.TAG_NAME, 'button')\n",
    "actions.click(akzeptieren).perform()\n",
    "wait(10)\n",
    "sleep(0.5)\n",
    "\n",
    "# 3.1 - \n",
    "scroller = driver.find_element(By.CLASS_NAME, 'infinite-scroller__show-more-button')\n",
    "\n",
    "scroll_down(4)\n",
    "\n",
    "# 4 -  Take Infos from Page\n",
    "# Headers, Company, City, Description\n",
    "H, P, C, O = 'base-search-card__title', 'job-search-card__listdate', 'hidden-nested-link', 'job-search-card__location'\n",
    "list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O)\n",
    "\n",
    "#description = driver.find_elements(By.CLASS_NAME, 'resultlist-1pq4x2u')\n",
    "result = driver.find_elements(By.CLASS_NAME, 'results-context-header__context')\n",
    "\n",
    "\n",
    "# Link Lists\n",
    "links = driver.find_elements(By.CLASS_NAME, 'base-card__full-link')\n",
    "list_link = [link.get_attribute('href') for link in links]\n",
    "\n",
    "print('Header',len(list_header), 'Publish',len(list_publish), 'Company',len(list_company), 'Ort',len(list_ort), 'Desc', len(list_description), 'Link',len(list_link))\n",
    "\n",
    "# Total Search Page Number\n",
    "list_result = [res.text for res in result]\n",
    "print(f'Number of Jobs Pages = {list_result}')\n",
    "\n",
    "\n",
    "# 4.2 - DataFrame df\n",
    "d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company=np.array(list_company), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "df = pd.DataFrame.from_dict(d, orient='index')\n",
    "df = df.T\n",
    "df['description'] = None\n",
    "df['website'] = website_name\n",
    "\n",
    "# 4.4 Save Data as csv and xlsx    \n",
    "print(f'DataFrame End : {df.shape}')\n",
    "# 4.3 - Save DataFrame\n",
    "# 4.3.1 - to csv\n",
    "df.loc[df.website =='linkedin', 'city'] = df.loc[df.website =='linkedin', 'city'].str.replace(', Kuzey Ren-Vestfalya, Almanya', '')\n",
    "df.to_csv(f'{path}/{job_name2}-{time_}.csv', mode='a', index=False, header=False)\n",
    "\n",
    "# 4.3.2 - to excel\n",
    "# install openpyxl\n",
    "#df.to_excel(f'{path}/{job_name2}-{time_}.xlsx', sheet_name='Sheet3')\n",
    "\n",
    "end =datetime.now() \n",
    "print('Code Runned No Problem')\n",
    "print(f'Time = {end - start}')\n",
    "sleep(5)\n",
    "driver.quit()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f658a5b4-9075-4ccc-b672-4c0de00b0da5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('---------------------- StepStone Job Searching Selenium Project ----------------------')\n",
    "start=datetime.now()  \n",
    "# 0 Link Descriptions\n",
    "link_original_stepstone = 'https://www.stepstone.de/jobs/data-analyst/in-rietberg?radius=50&page=2'\n",
    "\n",
    "website_name = 'stepstone'\n",
    "job_name = 'Data Analyst'\n",
    "ort_ = 'Rietberg'\n",
    "radius = 50\n",
    "page_number = 1\n",
    "\n",
    "#  1 - Create Driver\n",
    "Path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/chromedriver'\n",
    "driver = webdriver.Chrome(Path)\n",
    "\n",
    "#  2 - Go to Website\n",
    "job_link = job_name.replace(' ', '-').lower()\n",
    "ort_link = ort_.lower()\n",
    "link = f'https://www.stepstone.de/jobs/{job_link}/in-{ort_link}?radius={radius}&page={page_number}'\n",
    "\n",
    "driver.get(link)\n",
    "wait(10)\n",
    "sleep(2)\n",
    "\n",
    "#  3 - ActionChain Object created\n",
    "# 3.1 - Click Banned Accept\n",
    "ID = 'ccmgt_explicit_accept'\n",
    "click_bann_byID(ID)\n",
    "\n",
    "# 4 -  Take Infos from Page\n",
    "# Headers, Publish_Time ,Company, City\n",
    "H, P, C, O = 'resultlist-12iu5pk', 'resultlist-3asi6i', 'resultlist-1v262t5', 'resultlist-dettfq'\n",
    "list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O)\n",
    "\n",
    "header = driver.find_elements(By.CLASS_NAME, H)\n",
    "list_link = [link.get_attribute('href') for link in header]\n",
    "\n",
    "print(list_link)\n",
    "\n",
    "end =datetime.now() \n",
    "print('Code Runned No Problem')\n",
    "print(f'Time = {end - start}')\n",
    "sleep(5)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dfc69b-86da-4164-90a0-9b8e5cde5817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_elements_HPCO(H,P,C,O):\n",
    "    if website_name == 'jobware':\n",
    "        header = driver.find_elements(By.TAG_NAME, H)\n",
    "    else:\n",
    "        header = driver.find_elements(By.CLASS_NAME, H)\n",
    "    publish = driver.find_elements(By.CLASS_NAME, P)\n",
    "    company = driver.find_elements(By.CLASS_NAME, C)\n",
    "    ort = driver.find_elements(By.CLASS_NAME, O) \n",
    "\n",
    "    list_header = [title.text for title in header]\n",
    "    list_publish = [pub.text for pub in publish]\n",
    "    list_company = [comp.text for comp in company]\n",
    "    list_ort = [o.text for o in ort]\n",
    "    return list_header, list_publish, list_company, list_ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0029613d-bac3-4d7d-98f6-3278e5c7632e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('---------------------- Jobware Job Searching Selenium Project ----------------------')\n",
    "\n",
    "start=datetime.now()  \n",
    "# 0 Link Descriptions\n",
    "link_original = 'https://www.jobware.de/jobsuche?jw_jobname=data%20analyst&jw_jobort=333**%20Rietberg&jw_ort_distance=50'\n",
    "\n",
    "website_name = 'jobware'\n",
    "job_name = 'Data Analyst'\n",
    "ort_ = 'Rietberg'\n",
    "radius = 50\n",
    "page_number = 0\n",
    "\n",
    "#  1 - Create Driver\n",
    "Path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/chromedriver'\n",
    "driver = webdriver.Chrome(Path)\n",
    "\n",
    "#  2 - Go to Website\n",
    "job_link = job_name.replace(' ', '%20').lower()\n",
    "ort_link = ort_.capitalize()\n",
    "link = f'https://www.jobware.de/jobsuche?jw_jobname={job_link}&jw_jobort=333**%20{ort_}&jw_ort_distance={radius}'\n",
    "\n",
    "driver.get(link)\n",
    "wait(10)\n",
    "sleep(2)\n",
    "\n",
    "#  3 - ActionChain Object created\n",
    "# 3.1 - Click Banned Accept\n",
    "actions = ActionChains(driver)\n",
    "akzeptieren = driver.find_element(By.XPATH, '/html/body/div[1]/div/div[3]/div[2]/button')\n",
    "actions.click(akzeptieren).perform()\n",
    "wait(10)\n",
    "sleep(0.5)\n",
    "#dsgvo-1B76C4DA4B-orange dsgvo-1B76C4DA4B-accept\n",
    "\n",
    "# 4 -  Take Infos from Page\n",
    "# Headers, Company, City, Description\n",
    "H, P, C, O = 'h2', 'date', 'company', 'location'\n",
    "list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O)\n",
    "description = driver.find_elements(By.CLASS_NAME, 'task')\n",
    "list_description = [des.text for des in description]\n",
    "\n",
    "print('Header',len(list_header), 'Publish',len(list_publish), 'Company',len(list_company), 'Ort',len(list_ort), 'Desc', len(list_description))\n",
    "\n",
    "# Total Search Page Number\n",
    "result = driver.find_elements(By.CLASS_NAME, 'result-sort')\n",
    "list_result = [res.text for res in result]\n",
    "print(list_result)\n",
    "\n",
    "\n",
    "links = driver.find_elements(By.CLASS_NAME, 'job')\n",
    "list_link = [link.get_attribute('href') for link in links]\n",
    "\n",
    "print(list_link)\n",
    "print(len(list_link))\n",
    "end =datetime.now() \n",
    "print('Code Runned No Problem')\n",
    "print(f'Time = {end - start}')\n",
    "sleep(5)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed15f61-410d-4795-aa1b-4ed7b35152fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9adf53-167a-4d82-9930-d34b3e3ad5f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('---------------------- Linkedin Job Searching Selenium Project ----------------------')\n",
    "\n",
    "def scroll_down(x):\n",
    "    n=0\n",
    "    while n < x:\n",
    "        n+=1\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        sleep(1.5)\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        sleep(1.5)\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        sleep(1.5)\n",
    "        actions.key_down(Keys.PAGE_UP).perform()\n",
    "        sleep(0.10)\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        wait(10)\n",
    "        sleep(2.5)\n",
    "\n",
    "start=datetime.now()  \n",
    "# 0 Link Descriptions\n",
    "link_original = 'https://www.linkedin.com/jobs/search/?currentJobId=3199974140&distance=25&keywords=data%20analyst&location=Rietberg' \n",
    "\n",
    "website_name =  'linkedin'\n",
    "radius = 40\n",
    "page_number = 1\n",
    "\n",
    "#  1 - Create Driver\n",
    "Path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/chromedriver'\n",
    "driver = webdriver.Chrome(Path)\n",
    "\n",
    "#  2 - Go to Website\n",
    "job_link = job_name.replace(' ', '%20').lower()\n",
    "\n",
    "link2 = f'https://www.linkedin.com/jobs/search/?distance=25&keywords={job_link}&location={ort_}'\n",
    "driver.get(link2)\n",
    "wait(10)\n",
    "sleep(2)\n",
    "\n",
    "\n",
    "#  3 - ActionChain Object created\n",
    "# 3.1 - Click Banned Accept\n",
    "actions = ActionChains(driver)\n",
    "akzeptieren = driver.find_element(By.TAG_NAME, 'button')\n",
    "actions.click(akzeptieren).perform()\n",
    "wait(10)\n",
    "sleep(0.5)\n",
    "\n",
    "# 3.1 - \n",
    "scroller = driver.find_element(By.CLASS_NAME, 'infinite-scroller__show-more-button')\n",
    "\n",
    "scroll_down(2)\n",
    "\n",
    "# 4 -  Take Infos from Page\n",
    "# Headers, Company, City, Description\n",
    "header = driver.find_elements(By.CLASS_NAME, 'base-search-card__title')\n",
    "publish = driver.find_elements(By.CLASS_NAME, 'job-search-card__listdate')\n",
    "company = driver.find_elements(By.CLASS_NAME, 'hidden-nested-link')\n",
    "ort = driver.find_elements(By.CLASS_NAME, 'job-search-card__location') \n",
    "#description = driver.find_elements(By.CLASS_NAME, 'resultlist-1pq4x2u')\n",
    "result = driver.find_elements(By.CLASS_NAME, 'results-context-header__context')\n",
    "\n",
    "\n",
    "# 4.1 -\n",
    "list_header = [title.text for title in header]\n",
    "list_publish = [pub.text for pub in publish]\n",
    "list_company = [comp.text for comp in company]\n",
    "list_ort = [o.text for o in ort]\n",
    "#list_description = [des.text for des in description]\n",
    "\n",
    "print('Header',len(list_header), 'Publish',len(list_publish), 'Company',len(list_company), 'Ort',len(list_ort))\n",
    "\n",
    "# Total Search Page Number\n",
    "list_result = [res.text for res in result]\n",
    "print(f'Number of Jobs Pages = {list_result}')\n",
    "\n",
    "\n",
    "links = driver.find_elements(By.CLASS_NAME, 'base-card__full-link')\n",
    "list_link = [link.get_attribute('href') for link in links]\n",
    "\n",
    "#print(list_link)\n",
    "print(len(list_link))\n",
    "\n",
    "\n",
    "end =datetime.now() \n",
    "print('Code Runned No Problem')\n",
    "print(f'Time = {end - start}')\n",
    "sleep(10)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f0d4a6-7057-4b73-b055-d41b41e6c634",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(list_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d944397-0020-47fc-a6bd-ad51de9af3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_link[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515e5f1-3700-4611-bc25-f17e28d76200",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c99cae8-6313-4e24-a825-67c9c97275fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
