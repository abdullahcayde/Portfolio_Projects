{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7746b00f-5b5a-4866-831d-12b56c715dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f68a27f-889d-4c30-830e-1e1c54a38a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep(x):\n",
    "    time.sleep(x)\n",
    "    \n",
    "def wait(x):\n",
    "    driver.implicitly_wait(x)\n",
    "    \n",
    "def click_bann_byID(ID):\n",
    "    actions = ActionChains(driver)\n",
    "    akzeptieren = driver.find_element(By.ID, ID)\n",
    "    actions.click(akzeptieren).perform()\n",
    "    wait(10)\n",
    "    sleep(0.5)\n",
    "\n",
    "def find_elements_HPCO(H,P,C,O):\n",
    "    if website_name == 'jobware':\n",
    "        header = driver.find_elements(By.TAG_NAME, H)\n",
    "    else:\n",
    "        header = driver.find_elements(By.CLASS_NAME, H)\n",
    "    publish = driver.find_elements(By.CLASS_NAME, P)\n",
    "    company = driver.find_elements(By.CLASS_NAME, C)\n",
    "    ort = driver.find_elements(By.CLASS_NAME, O) \n",
    "\n",
    "    list_header = [title.text for title in header]\n",
    "    list_publish = [pub.text for pub in publish]\n",
    "    list_company = [comp.text for comp in company]\n",
    "    list_ort = [o.text for o in ort]\n",
    "    return list_header, list_publish, list_company, list_ort\n",
    "    \n",
    "def scroll_down(x):\n",
    "    n=0\n",
    "    while n < x:\n",
    "        n+=1\n",
    "        driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight)\", \"\")\n",
    "        wait(10)\n",
    "        sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f24bb0e-db35-4c09-950f-541b8871c539",
   "metadata": {},
   "source": [
    "# 01 - STEPSTONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "962f38df-d454-44d7-afcc-8b1e7917ae67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- StepStone Job Searching Selenium Project ----------------------\n",
      "Header 25 Publish 25 Company 25 Ort 25 desc 25\n",
      "Number of Jobs Pages = 22\n",
      "Page Number : 2, DataFrame Shape : (25, 5)\n",
      "Page Number : 3, DataFrame Shape : (25, 5)\n",
      "Page Number : 4, DataFrame Shape : (25, 5)\n",
      "Page Number : 5, DataFrame Shape : (25, 5)\n",
      "Page Number : 6, DataFrame Shape : (25, 5)\n",
      "Page Number : 7, DataFrame Shape : (25, 5)\n",
      "Page Number : 8, DataFrame Shape : (25, 5)\n",
      "Page Number : 9, DataFrame Shape : (25, 5)\n",
      "Page Number : 10, DataFrame Shape : (25, 5)\n",
      "Page Number : 11, DataFrame Shape : (25, 5)\n",
      "Page Number : 12, DataFrame Shape : (25, 5)\n",
      "Page Number : 13, DataFrame Shape : (25, 5)\n",
      "Page Number : 14, DataFrame Shape : (25, 5)\n",
      "Page Number : 15, DataFrame Shape : (25, 5)\n",
      "Page Number : 16, DataFrame Shape : (25, 5)\n",
      "Page Number : 17, DataFrame Shape : (25, 5)\n",
      "Page Number : 18, DataFrame Shape : (25, 5)\n",
      "Page Number : 19, DataFrame Shape : (25, 5)\n",
      "Page Number : 20, DataFrame Shape : (25, 5)\n",
      "Page Number : 21, DataFrame Shape : (25, 5)\n",
      "Page Number : 22, DataFrame Shape : (5, 5)\n",
      "DataFrame End : (530, 5)\n",
      "Code Runned No Problem\n",
      "Time = 0:04:06.496023\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Title : Web Scrapping by Selenium \n",
    "Project Purpose: From StepStone scrap data for some Job Titels\n",
    "1 - Create Driver\n",
    "2 - Go to Website\n",
    "3 - Create ActionChain Object\n",
    "    3.1 - Click Banned Accept\n",
    "4 - Take Title and Infos from Page\n",
    "    4.1 - Create Lists \n",
    "    4.2 - Create DataFrame\n",
    "    4.3 - Repeat Process\n",
    "    4.4 - Print and Save DataFrame\n",
    "'''\n",
    "\n",
    "print('---------------------- StepStone Job Searching Selenium Project ----------------------')\n",
    "start=datetime.now()  \n",
    "# 0 Link Descriptions\n",
    "link_original_stepstone = 'https://www.stepstone.de/jobs/data-analyst/in-rietberg?radius=50&page=2'\n",
    "\n",
    "website_name = 'stepstone'\n",
    "job_name = 'Data Analyst'\n",
    "ort_ = 'Rietberg'\n",
    "radius = 50\n",
    "page_number = 1\n",
    "\n",
    "#  1 - Create Driver\n",
    "Path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/chromedriver'\n",
    "driver = webdriver.Chrome(Path)\n",
    "\n",
    "#  2 - Go to Website\n",
    "job_link = job_name.replace(' ', '-').lower()\n",
    "ort_link = ort_.lower()\n",
    "link = f'https://www.stepstone.de/jobs/{job_link}/in-{ort_link}?radius={radius}&page={page_number}'\n",
    "\n",
    "driver.get(link)\n",
    "wait(10)\n",
    "sleep(2)\n",
    "\n",
    "#  3 - ActionChain Object created\n",
    "# 3.1 - Click Banned Accept\n",
    "ID = 'ccmgt_explicit_accept'\n",
    "click_bann_byID(ID)\n",
    "\n",
    "# 4 -  Take Infos from Page\n",
    "# Headers, Publish_Time ,Company, City\n",
    "H, P, C, O = 'resultlist-12iu5pk', 'resultlist-3asi6i', 'resultlist-1v262t5', 'resultlist-dettfq'\n",
    "list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O)\n",
    "\n",
    "# Description and Page number of results\n",
    "description = driver.find_elements(By.CLASS_NAME, 'resultlist-1pq4x2u')\n",
    "result = driver.find_elements(By.CLASS_NAME, 'resultlist-xeyevn')\n",
    "\n",
    "# 4.1 - Get Texts for each finding\n",
    "list_description = [des.text for des in description]\n",
    "print('Header',len(list_header), 'Publish',len(list_publish), 'Company',len(list_company), 'Ort',len(list_ort), 'desc', len(list_description))\n",
    "\n",
    "# Total Search Page Number\n",
    "list_result = [res.text for res in result]\n",
    "number_of_page = int(list_result[0].split(' ')[-1])\n",
    "print(f'Number of Jobs Pages = {number_of_page}')\n",
    "\n",
    "# 4.2 - DataFrame df\n",
    "d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company_name=np.array(list_company), city=np.array(list_ort) , description=np.array(list_description))\n",
    "df = pd.DataFrame.from_dict(d, orient='index')\n",
    "df = df.T\n",
    "\n",
    "\n",
    "# 4.3 Repeat Process for every Web Page\n",
    "while  page_number < number_of_page:\n",
    "    page_number+=1\n",
    "    \n",
    "    # 4.1 - Go to another page\n",
    "    link = f'https://www.stepstone.de/jobs/{job_link}/in-{ort_link}?radius={radius}&page={page_number}'\n",
    "    driver.get(link)\n",
    "    wait(10)\n",
    "    sleep(1.5)\n",
    "    \n",
    "    # 4.2 - Find the elements and get the Texts\n",
    "    list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O) \n",
    "    description = driver.find_elements(By.CLASS_NAME, 'resultlist-1pq4x2u')\n",
    "    list_description = [des.text for des in description]\n",
    " \n",
    "    # 4.3 - Create new page Dataframe\n",
    "    d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company_name=np.array(list_company), city=np.array(list_ort) , description=np.array(list_description))\n",
    "    df2 = pd.DataFrame.from_dict(d, orient='index')\n",
    "    df2 = df2.T\n",
    "    \n",
    "    # 4.4 - Concatenate the DataFrames\n",
    "    df = pd.concat([df,df2], axis=0, ignore_index=True)\n",
    "    print(f'Page Number : {page_number}, DataFrame Shape : {df2.shape}')\n",
    "    \n",
    "\n",
    "# 4.4 Save Data as csv and xlsx    \n",
    "print(f'DataFrame End : {df.shape}')\n",
    "df['website'] = website_name\n",
    "# 4.3 - Save DataFrame\n",
    "# 4.3.1 - to csv\n",
    "path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/data'\n",
    "job_name2 = job_name.replace(' ', '-')\n",
    "time_ = datetime.today().strftime('%Y-%m-%d')\n",
    "df.to_csv(f'{path}/{job_name2}-{time_}.csv', index=False)\n",
    "\n",
    "end =datetime.now() \n",
    "print('Code Runned No Problem')\n",
    "print(f'Time = {end - start}')\n",
    "sleep(5)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bba6fe-9b6e-4110-8eb6-2c9444a77965",
   "metadata": {},
   "source": [
    "# 02 - JOBWARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74123825-811b-4b9e-b02f-1d35ac17737b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- Jobware Job Searching Selenium Project ----------------------\n",
      "Header 12 Publish 12 Company 12 Ort 12 Desc 11\n",
      "['12 Treffer\\nSortierung: Relevanz - Datum']\n",
      "DataFrame End : (12, 5)\n",
      "Code Runned No Problem\n",
      "Time = 0:00:12.610382\n"
     ]
    }
   ],
   "source": [
    "print('---------------------- Jobware Job Searching Selenium Project ----------------------')\n",
    "\n",
    "start=datetime.now()  \n",
    "# 0 Link Descriptions\n",
    "link_original = 'https://www.jobware.de/jobsuche?jw_jobname=data%20analyst&jw_jobort=333**%20Rietberg&jw_ort_distance=50'\n",
    "\n",
    "website_name = 'jobware'\n",
    "job_name = 'Data Analyst'\n",
    "ort_ = 'Rietberg'\n",
    "radius = 50\n",
    "page_number = 0\n",
    "\n",
    "#  1 - Create Driver\n",
    "Path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/chromedriver'\n",
    "driver = webdriver.Chrome(Path)\n",
    "\n",
    "#  2 - Go to Website\n",
    "job_link = job_name.replace(' ', '%20').lower()\n",
    "ort_link = ort_.capitalize()\n",
    "link = f'https://www.jobware.de/jobsuche?jw_jobname={job_link}&jw_jobort=333**%20{ort_}&jw_ort_distance={radius}'\n",
    "\n",
    "driver.get(link)\n",
    "wait(10)\n",
    "sleep(2)\n",
    "\n",
    "#  3 - ActionChain Object created\n",
    "# 3.1 - Click Banned Accept\n",
    "actions = ActionChains(driver)\n",
    "akzeptieren = driver.find_element(By.XPATH, '/html/body/div[1]/div/div[3]/div[2]/button')\n",
    "actions.click(akzeptieren).perform()\n",
    "wait(10)\n",
    "sleep(0.5)\n",
    "#dsgvo-1B76C4DA4B-orange dsgvo-1B76C4DA4B-accept\n",
    "\n",
    "# 4 -  Take Infos from Page\n",
    "# Headers, Company, City, Description\n",
    "H, P, C, O = 'h2', 'date', 'company', 'location'\n",
    "list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O)\n",
    "description = driver.find_elements(By.CLASS_NAME, 'task')\n",
    "list_description = [des.text for des in description]\n",
    "\n",
    "print('Header',len(list_header), 'Publish',len(list_publish), 'Company',len(list_company), 'Ort',len(list_ort), 'Desc', len(list_description))\n",
    "\n",
    "# Total Search Page Number\n",
    "result = driver.find_elements(By.CLASS_NAME, 'result-sort')\n",
    "list_result = [res.text for res in result]\n",
    "print(list_result)\n",
    "\n",
    "# 4.2 - DataFrame df\n",
    "d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company_name=np.array(list_company), city=np.array(list_ort) , description=np.array(list_description))\n",
    "df = pd.DataFrame.from_dict(d, orient='index')\n",
    "df = df.T\n",
    "\n",
    "# 4.4 Save Data as csv and xlsx    \n",
    "print(f'DataFrame End : {df.shape}')\n",
    "df['website'] = website_name\n",
    "# 4.3 - Save DataFrame\n",
    "# 4.3.1 - to csv\n",
    "df.to_csv(f'{path}/{job_name2}-{time_}.csv', mode='a', index=False, header=False)\n",
    "\n",
    "end =datetime.now() \n",
    "print('Code Runned No Problem')\n",
    "print(f'Time = {end - start}')\n",
    "sleep(5)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abde48a-5765-4f02-81fd-b32ce46555e1",
   "metadata": {},
   "source": [
    "# 03 - LINKEDIN (Chrome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dbf2fbe-1a18-43d0-b510-6c6015993c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- Linkedin Job Searching Selenium Project ----------------------\n",
      "Header 175 Publish 170 Company 162 Ort 175\n",
      "Number of Jobs Pages = ['Rietberg, Kuzey Ren-Vestfalya, Almanya konumunda 847 Data Analyst iş ilanı (20 yeni)']\n",
      "DataFrame End : (175, 6)\n",
      "Code Runned No Problem\n",
      "Time = 0:00:38.961719\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>publish</th>\n",
       "      <th>company_name</th>\n",
       "      <th>city</th>\n",
       "      <th>description</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst (w/m/d) Power BI mit Remote-Anteil</td>\n",
       "      <td>1 hafta önce</td>\n",
       "      <td>ATLAS TITAN Mitte GmbH</td>\n",
       "      <td>Gütersloh, Kuzey Ren-Vestfalya, Almanya</td>\n",
       "      <td>None</td>\n",
       "      <td>linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst / Scientist (m/w/d)</td>\n",
       "      <td>2 hafta önce</td>\n",
       "      <td>Dr. Wolff Group</td>\n",
       "      <td>Bielefeld, Kuzey Ren-Vestfalya, Almanya</td>\n",
       "      <td>None</td>\n",
       "      <td>linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data / Business Analyst (m/w/d)</td>\n",
       "      <td>2 hafta önce</td>\n",
       "      <td>Dr. Wolff Group</td>\n",
       "      <td>Bielefeld, Kuzey Ren-Vestfalya, Almanya</td>\n",
       "      <td>None</td>\n",
       "      <td>linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CRM Data Analyst (m/w/d)</td>\n",
       "      <td>1 gün önce</td>\n",
       "      <td>hachmeister+partner</td>\n",
       "      <td>Bielefeld, Kuzey Ren-Vestfalya, Almanya</td>\n",
       "      <td>None</td>\n",
       "      <td>linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst für Datenmodellierung und Kundenb...</td>\n",
       "      <td>1 ay önce</td>\n",
       "      <td>Lurse</td>\n",
       "      <td>Salzkotten, Kuzey Ren-Vestfalya, Almanya</td>\n",
       "      <td>None</td>\n",
       "      <td>linkedin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title       publish  \\\n",
       "0    Data Analyst (w/m/d) Power BI mit Remote-Anteil  1 hafta önce   \n",
       "1                   Data Analyst / Scientist (m/w/d)  2 hafta önce   \n",
       "2                    Data / Business Analyst (m/w/d)  2 hafta önce   \n",
       "3                           CRM Data Analyst (m/w/d)    1 gün önce   \n",
       "4  Data Analyst für Datenmodellierung und Kundenb...     1 ay önce   \n",
       "\n",
       "             company_name                                      city  \\\n",
       "0  ATLAS TITAN Mitte GmbH   Gütersloh, Kuzey Ren-Vestfalya, Almanya   \n",
       "1         Dr. Wolff Group   Bielefeld, Kuzey Ren-Vestfalya, Almanya   \n",
       "2         Dr. Wolff Group   Bielefeld, Kuzey Ren-Vestfalya, Almanya   \n",
       "3     hachmeister+partner   Bielefeld, Kuzey Ren-Vestfalya, Almanya   \n",
       "4                   Lurse  Salzkotten, Kuzey Ren-Vestfalya, Almanya   \n",
       "\n",
       "  description   website  \n",
       "0        None  linkedin  \n",
       "1        None  linkedin  \n",
       "2        None  linkedin  \n",
       "3        None  linkedin  \n",
       "4        None  linkedin  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('---------------------- Linkedin Job Searching Selenium Project ----------------------')\n",
    "def sleep(x):\n",
    "    time.sleep(x)\n",
    "def wait(x):\n",
    "    driver.implicitly_wait(x)\n",
    "    \n",
    "\n",
    "    #sleep(1.5)\n",
    "    #more_option = driver.find_element(By.CLASS_NAME, 'infinite-scroller__show-more-button')\n",
    "    #actions.click(more_option).perform()\n",
    "    #wait(10)\n",
    "    #sleep(0.5)    \n",
    "    \n",
    "\n",
    "start=datetime.now()  \n",
    "# 0 Link Descriptions\n",
    "link_original = 'https://www.linkedin.com/jobs/search/?currentJobId=3199974140&distance=25&keywords=data%20analyst&location=Rietberg' \n",
    "\n",
    "website_name =  'linkedin'\n",
    "radius = 40\n",
    "page_number = 1\n",
    "\n",
    "#  1 - Create Driver\n",
    "Path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/chromedriver'\n",
    "driver = webdriver.Chrome(Path)\n",
    "\n",
    "#  2 - Go to Website\n",
    "job_link = job_name.replace(' ', '%20').lower()\n",
    "\n",
    "link2 = f'https://www.linkedin.com/jobs/search/?distance=25&keywords={job_link}&location={ort_}'\n",
    "driver.get(link2)\n",
    "wait(10)\n",
    "sleep(2)\n",
    "\n",
    "\n",
    "#  3 - ActionChain Object created\n",
    "# 3.1 - Click Banned Accept\n",
    "actions = ActionChains(driver)\n",
    "akzeptieren = driver.find_element(By.TAG_NAME, 'button')\n",
    "actions.click(akzeptieren).perform()\n",
    "wait(10)\n",
    "sleep(0.5)\n",
    "\n",
    "# 3.1 - \n",
    "scroller = driver.find_element(By.CLASS_NAME, 'infinite-scroller__show-more-button')\n",
    "\n",
    "scroll_down(7)\n",
    "\n",
    "# 4 -  Take Infos from Page\n",
    "# Headers, Company, City, Description\n",
    "header = driver.find_elements(By.CLASS_NAME, 'base-search-card__title')\n",
    "publish = driver.find_elements(By.CLASS_NAME, 'job-search-card__listdate')\n",
    "company = driver.find_elements(By.CLASS_NAME, 'hidden-nested-link')\n",
    "ort = driver.find_elements(By.CLASS_NAME, 'job-search-card__location') \n",
    "#description = driver.find_elements(By.CLASS_NAME, 'resultlist-1pq4x2u')\n",
    "result = driver.find_elements(By.CLASS_NAME, 'results-context-header__context')\n",
    "\n",
    "# 4.1 -\n",
    "list_header = [title.text for title in header]\n",
    "list_publish = [pub.text for pub in publish]\n",
    "list_company = [comp.text for comp in company]\n",
    "list_ort = [o.text for o in ort]\n",
    "#list_description = [des.text for des in description]\n",
    "\n",
    "print('Header',len(list_header), 'Publish',len(list_publish), 'Company',len(list_company), 'Ort',len(list_ort))\n",
    "\n",
    "# Total Search Page Number\n",
    "list_result = [res.text for res in result]\n",
    "print(f'Number of Jobs Pages = {list_result}')\n",
    "\n",
    "# 4.2 - DataFrame df\n",
    "d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company_name=np.array(list_company), city=np.array(list_ort))\n",
    "df = pd.DataFrame.from_dict(d, orient='index')\n",
    "df = df.T\n",
    "df['description'] = None\n",
    "df['website'] = website_name\n",
    "\n",
    "# 4.4 Save Data as csv and xlsx    \n",
    "print(f'DataFrame End : {df.shape}')\n",
    "# 4.3 - Save DataFrame\n",
    "# 4.3.1 - to csv\n",
    "df.to_csv(f'{path}/{job_name2}-{time_}.csv', mode='a', index=False, header=False)\n",
    "\n",
    "# 4.3.2 - to excel\n",
    "# install openpyxl\n",
    "#df.to_excel(f'{path}/{job_name2}-{time_}.xlsx', sheet_name='Sheet3')\n",
    "\n",
    "end =datetime.now() \n",
    "print('Code Runned No Problem')\n",
    "print(f'Time = {end - start}')\n",
    "sleep(5)\n",
    "driver.quit()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea6746b-19b3-46ff-a774-18cb5356b475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "985196a8-e70c-4674-b1b3-8bf08a30f8af",
   "metadata": {},
   "source": [
    "# Read Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75c0f978-6ade-4015-9333-088ce42757de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>publish</th>\n",
       "      <th>company_name</th>\n",
       "      <th>city</th>\n",
       "      <th>description</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Analyst - Web (m/w/d)</td>\n",
       "      <td>vor 5 Tagen</td>\n",
       "      <td>Neue Westfälische GmbH &amp; Co. KG</td>\n",
       "      <td>Bielefeld</td>\n",
       "      <td>Wir suchen nach einem Data Analyst/Data Scient...</td>\n",
       "      <td>stepstone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ERP Specialist / Business Data Analyst (m/w/d)</td>\n",
       "      <td>vor 1 Woche</td>\n",
       "      <td>DAYTON PROGRESS GmbH</td>\n",
       "      <td>Hamburg, Köln, Bielefeld, Hannover, Berlin, Le...</td>\n",
       "      <td>Aktuell sucht Dayton Progress einen ERP Specia...</td>\n",
       "      <td>stepstone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst / Scientist (m/w/d)</td>\n",
       "      <td>vor 1 Woche</td>\n",
       "      <td>eWolff GmbH</td>\n",
       "      <td>Bielefeld</td>\n",
       "      <td>Finde Deine Rolle und verstärke unser Team Dat...</td>\n",
       "      <td>stepstone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consultant Data Analyst (m/w/d)</td>\n",
       "      <td>vor 2 Tagen</td>\n",
       "      <td>Arvato Systems GmbH</td>\n",
       "      <td>Gütersloh</td>\n",
       "      <td>Und darum suchen wir dich als Consultant Data ...</td>\n",
       "      <td>stepstone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data / Business Analyst (m/w/d)</td>\n",
       "      <td>vor 1 Woche</td>\n",
       "      <td>eWolff GmbH</td>\n",
       "      <td>Bielefeld</td>\n",
       "      <td>Finde Deine Rolle und verstärke unser Team Dat...</td>\n",
       "      <td>stepstone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        job_title      publish  \\\n",
       "0          Data Scientist / Analyst - Web (m/w/d)  vor 5 Tagen   \n",
       "1  ERP Specialist / Business Data Analyst (m/w/d)  vor 1 Woche   \n",
       "2                Data Analyst / Scientist (m/w/d)  vor 1 Woche   \n",
       "3                 Consultant Data Analyst (m/w/d)  vor 2 Tagen   \n",
       "4                 Data / Business Analyst (m/w/d)  vor 1 Woche   \n",
       "\n",
       "                      company_name  \\\n",
       "0  Neue Westfälische GmbH & Co. KG   \n",
       "1             DAYTON PROGRESS GmbH   \n",
       "2                      eWolff GmbH   \n",
       "3              Arvato Systems GmbH   \n",
       "4                      eWolff GmbH   \n",
       "\n",
       "                                                city  \\\n",
       "0                                          Bielefeld   \n",
       "1  Hamburg, Köln, Bielefeld, Hannover, Berlin, Le...   \n",
       "2                                          Bielefeld   \n",
       "3                                          Gütersloh   \n",
       "4                                          Bielefeld   \n",
       "\n",
       "                                         description    website  \n",
       "0  Wir suchen nach einem Data Analyst/Data Scient...  stepstone  \n",
       "1  Aktuell sucht Dayton Progress einen ERP Specia...  stepstone  \n",
       "2  Finde Deine Rolle und verstärke unser Team Dat...  stepstone  \n",
       "3  Und darum suchen wir dich als Consultant Data ...  stepstone  \n",
       "4  Finde Deine Rolle und verstärke unser Team Dat...  stepstone  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = pd.read_csv(f'{path}/{job_name2}-{time_}.csv')\n",
    "df = jobs.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a25f2101-b313-44e4-a6c2-af205ac811d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = jobs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8ed9cb4-24e3-49f3-8973-bc0287035484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(717, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a4fb6b2-b22d-47ee-9fa8-0ef69f0e78f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 717 entries, 0 to 716\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   job_title     717 non-null    object\n",
      " 1   publish       712 non-null    object\n",
      " 2   company_name  704 non-null    object\n",
      " 3   city          717 non-null    object\n",
      " 4   description   541 non-null    object\n",
      " 5   website       717 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 33.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00baa41-2cdf-4c67-841f-8b91e11ea7fb",
   "metadata": {},
   "source": [
    "## Dropn Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3e0c0445-71b0-4884-8a9e-830f0112d79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_title         0\n",
       "publish           5\n",
       "company_name     13\n",
       "city              0\n",
       "description     176\n",
       "website           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "04a4c463-e917-4a36-8a26-a3dcc4c3dfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_title         0\n",
       "publish           0\n",
       "company_name      0\n",
       "city              0\n",
       "description     163\n",
       "website           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['company_name'], inplace=True)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88055030-5f0d-46ce-9091-a90af372cf47",
   "metadata": {},
   "source": [
    "## Drop Duplicated Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "797e37aa-0fbb-4a5a-ad10-b34dacd682c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_title       5\n",
       "publish         5\n",
       "company_name    5\n",
       "city            5\n",
       "description     5\n",
       "website         5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated(subset=['job_title', 'company_name', 'city', 'description'])].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b43fb224-039b-4b15-b6a0-c79f3f8eecac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_title       0\n",
       "publish         0\n",
       "company_name    0\n",
       "city            0\n",
       "description     0\n",
       "website         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset=['job_title', 'company_name', 'city', 'description'], inplace=True)\n",
    "df[df.duplicated(subset=['job_title', 'company_name', 'city', 'description'])].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "de12665d-81fd-42c0-9ae3-73c655a673a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699, 6)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ba85fa0-0b06-44d2-b356-7575ce7dbe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modify Publish Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "960438d1-bc4f-480d-a1e4-8f2c03d6c743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_column(column_name, old, new):\n",
    "    df[column_name] = df[column_name].str.replace(old, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5b139369-9587-41c4-adc8-287321fbdd13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5 tagen', '1 woche', '2 tagen', '3 tagen', '3 wochen', '4 tagen',\n",
       "       '2 wochen', '1 tag', '4 wochen', '2022-11-07', '6 tagen',\n",
       "       '1 monat', '29.10.2022', '27.10.2022', '24.10.2022', '26.10.2022',\n",
       "       '04.10.2022', '30.10.2022', '19.10.2022', '26.06.2022', '1 hafta',\n",
       "       '2 hafta', '1 gün', '1 ay', '4 gün', '3 hafta', '3 ay', '4 hafta',\n",
       "       '2 gün', '2 ay', '4 ay', '6 gün', '3 gün', '6 ay'], dtype=object)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "# print(d - datetime.timedelta(days=57)\n",
    "\n",
    "def replace_column(column_name, old, new):\n",
    "    df[column_name] = df[column_name].str.replace(old, new)\n",
    "\n",
    "# Rakam Secer String icinden\n",
    "#df.publish.str.replace('\\D+', '')\n",
    "\n",
    "# Fill NAN to no_info\n",
    "df.publish = df.publish.str.lower()\n",
    "df.publish.fillna('no_info', inplace=True)\n",
    "\n",
    "# Fill stunde to today\n",
    "time_ = datetime.today().strftime('%Y-%m-%d')\n",
    "df.publish.loc[df.publish.str.contains('stunden')] = time_\n",
    "\n",
    "# clean vor and önce\n",
    "replace_column('publish', 'vor', '')\n",
    "replace_column('publish', 'önce', '')\n",
    "\n",
    "# strip\n",
    "df.publish = df.publish.str.strip()\n",
    "\n",
    "#df.publish.loc[df.publish.str.contains('tag')] = df.publis\n",
    "df.publish.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4b66d645-93c8-4e89-bba1-ff9e5ef88f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>NTT DATA Business Solutions AG</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>FORTIS IT-Services GmbH</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>adesso SE</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>DATAGROUP</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Reply</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Arvato Systems</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Tourlane GmbH</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>PwC</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Takeaway.com</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Arvato Systems GmbH</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>GOLDBECK GmbH</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Arvato Infoscore GmbH</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>dSPACE GmbH</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Revolut Ltd. Zweigniederlassung Deutschland</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>HELLA</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>IU Internationale Hochschule</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>adesso orange AG</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Amazon Europe Core</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>HypoVereinsbank – Member of UniCredit</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>GOLDBECK</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Ratbacher GmbH</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Weidmüller Gruppe</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Riverty GmbH</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Dr. August Oetker Nahrungsmittel KG</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Amadeus FiRe AG</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    company_name  job_title\n",
       "180               NTT DATA Business Solutions AG         97\n",
       "104                      FORTIS IT-Services GmbH         24\n",
       "263                                    adesso SE         17\n",
       "78                                     DATAGROUP         13\n",
       "205                                        Reply         12\n",
       "27                                Arvato Systems         11\n",
       "238                                Tourlane GmbH         11\n",
       "199                                          PwC         11\n",
       "234                                 Takeaway.com          9\n",
       "28                           Arvato Systems GmbH          9\n",
       "111                                GOLDBECK GmbH          7\n",
       "23                         Arvato Infoscore GmbH          7\n",
       "270                                  dSPACE GmbH          7\n",
       "207  Revolut Ltd. Zweigniederlassung Deutschland          7\n",
       "120                                        HELLA          6\n",
       "140                 IU Internationale Hochschule          6\n",
       "265                             adesso orange AG          6\n",
       "21                            Amazon Europe Core          6\n",
       "129        HypoVereinsbank – Member of UniCredit          6\n",
       "110                                     GOLDBECK          6\n",
       "202                               Ratbacher GmbH          5\n",
       "255                            Weidmüller Gruppe          5\n",
       "211                                 Riverty GmbH          5\n",
       "90           Dr. August Oetker Nahrungsmittel KG          5\n",
       "20                               Amadeus FiRe AG          5"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('company_name')['job_title'].count().reset_index().sort_values('job_title', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0a66656d-c125-46d8-930d-1a0224427aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>publish</th>\n",
       "      <th>company_name</th>\n",
       "      <th>city</th>\n",
       "      <th>description</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>System Engineer Storage / NAS (m/w/d)</td>\n",
       "      <td>1 woche</td>\n",
       "      <td>Arvato Systems GmbH</td>\n",
       "      <td>Gütersloh</td>\n",
       "      <td>Hohes Know-how über die ONTAP Versionen Cluste...</td>\n",
       "      <td>stepstone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 job_title  publish         company_name  \\\n",
       "144  System Engineer Storage / NAS (m/w/d)  1 woche  Arvato Systems GmbH   \n",
       "\n",
       "          city                                        description    website  \n",
       "144  Gütersloh  Hohes Know-how über die ONTAP Versionen Cluste...  stepstone  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[['job_title', 'company_name', 'city', 'description']].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c7bc5926-84fe-496d-978d-ec85a854b83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job_title', 'publish', 'company_name', 'city', 'description',\n",
       "       'website'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6346b715-777c-46eb-a62a-2aa86449c116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
