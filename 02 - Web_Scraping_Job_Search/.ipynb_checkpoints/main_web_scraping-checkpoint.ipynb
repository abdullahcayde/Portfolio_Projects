{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5528f92-f973-4a97-bee5-895e01f101de",
   "metadata": {},
   "source": [
    "# \"Web Scraping with Selenium to Find a Job\" \n",
    "\n",
    "We will go through 3 main tasks to implement our project:\n",
    "\n",
    "Task 1: Importing libraries.\n",
    "\n",
    "Task 2: Define functions.\n",
    "\n",
    "Task 3: Web scraping with selenium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc42ec9-e367-454d-a1e7-290cfd658ce9",
   "metadata": {},
   "source": [
    "# Task 1 : Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7746b00f-5b5a-4866-831d-12b56c715dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfbfb6e-6233-4abe-9305-9b421869d22d",
   "metadata": {},
   "source": [
    "# Task 2 : Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f68a27f-889d-4c30-830e-1e1c54a38a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sleep function \n",
    "def sleep(x):\n",
    "    time.sleep(x)\n",
    "\n",
    "# Wait for a certain measure of time before throwing an exception\n",
    "def wait(x):\n",
    "    driver.implicitly_wait(x)\n",
    "\n",
    "# Click Function\n",
    "def click_bann_byID(ID):\n",
    "    actions = ActionChains(driver)\n",
    "    akzeptieren = driver.find_element(By.ID, ID)\n",
    "    actions.click(akzeptieren).perform()\n",
    "    wait(10)\n",
    "    sleep(0.5)\n",
    "\n",
    "# Find Elements Function\n",
    "def find_elements_HPCO(H,P,C,O):\n",
    "    if website_name == 'jobware':\n",
    "        header = driver.find_elements(By.TAG_NAME, H)\n",
    "    else:\n",
    "        header = driver.find_elements(By.CLASS_NAME, H)\n",
    "    publish = driver.find_elements(By.CLASS_NAME, P)\n",
    "    company = driver.find_elements(By.CLASS_NAME, C)\n",
    "    ort = driver.find_elements(By.CLASS_NAME, O) \n",
    "\n",
    "    list_header = [title.text for title in header]\n",
    "    list_publish = [pub.text for pub in publish]\n",
    "    list_company = [comp.text for comp in company]\n",
    "    list_ort = [o.text for o in ort]\n",
    "    return list_header, list_publish, list_company, list_ort\n",
    "\n",
    "# Scroll Down Function\n",
    "def scroll_down(x):\n",
    "    n=0\n",
    "    while n < x:\n",
    "        n+=1\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        sleep(1.5)\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        sleep(1.5)\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        sleep(1.5)\n",
    "        actions.key_down(Keys.PAGE_UP).perform()\n",
    "        sleep(0.10)\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        wait(10)\n",
    "        sleep(2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3feb03-1eeb-40e8-aa2a-48d4fea21a1a",
   "metadata": {},
   "source": [
    "# Web Scraping with Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f24bb0e-db35-4c09-950f-541b8871c539",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 01 - STEPSTONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "962f38df-d454-44d7-afcc-8b1e7917ae67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- StepStone Job Searching Selenium Project ----------------------\n",
      "Header 25 Publish 25 Company 25 Ort 25 Desc 25 Link 25\n",
      "Number of Jobs Pages = 3\n",
      "Page Number : 2, DataFrame Shape : (25, 6)\n",
      "Page Number : 3, DataFrame Shape : (3, 6)\n",
      "DataFrame End : (53, 6)\n",
      "Code Runned No Problem\n",
      "Time = 0:00:49.889326\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Title : Web Scrapping by Selenium \n",
    "Project Purpose: From StepStone scrap data for some Job Titels\n",
    "1 - Create Driver\n",
    "2 - Go to Website\n",
    "3 - Create ActionChain Object\n",
    "    3.1 - Click Banned \n",
    "4 - Take Title and Infos from Page\n",
    "    4.1 - Create Lists \n",
    "    4.2 - Create DataFrame\n",
    "    4.3 - Repeat Process\n",
    "    4.4 - Print and Save DataFrame\n",
    "'''\n",
    "\n",
    "print('---------------------- StepStone Job Searching Selenium Project ----------------------')\n",
    "start=datetime.now()  \n",
    "# Link Descriptions\n",
    "link_original_stepstone = 'https://www.stepstone.de/jobs/data-analyst/in-rietberg?radius=50&page=2'\n",
    "\n",
    "website_name = 'stepstone'\n",
    "#job_name = 'Data Analyst'\n",
    "job_name = 'Business Analyst'\n",
    "#job_name = 'Data Scientist'\n",
    "ort_ = 'Rietberg'\n",
    "radius = 50\n",
    "page_number = 1\n",
    "\n",
    "#  1 - Create Driver\n",
    "Path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/chromedriver'\n",
    "driver = webdriver.Chrome(Path)\n",
    "\n",
    "#  2 - Go to Website\n",
    "job_link = job_name.replace(' ', '-').lower()\n",
    "ort_link = ort_.lower()\n",
    "link = f'https://www.stepstone.de/jobs/{job_link}/in-{ort_link}?radius={radius}&page={page_number}'\n",
    "\n",
    "driver.get(link)\n",
    "wait(10)\n",
    "sleep(2)\n",
    "\n",
    "#  3 - ActionChain Object created\n",
    "# 3.1 - Click Banned Accept\n",
    "ID = 'ccmgt_explicit_accept'\n",
    "click_bann_byID(ID)\n",
    "\n",
    "\n",
    "# 4 -  Take Infos from Page\n",
    "# 4.1 - Headers, Publish_Time ,Company, City\n",
    "H, P, C, O = 'resultlist-1uvdp0v', 'resultlist-w7zbt7', 'resultlist-1va1dj8', 'resultlist-suri3e'\n",
    "list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O)\n",
    "\n",
    "# 4.2 - Description and Page number of results\n",
    "description = driver.find_elements(By.CLASS_NAME, 'resultlist-1fp8oay')\n",
    "result = driver.find_elements(By.CLASS_NAME, 'resultlist-1jx3vjx')\n",
    "\n",
    "\n",
    "# 4.3 - Get Links\n",
    "header = driver.find_elements(By.CLASS_NAME, H)\n",
    "list_link = [link.get_attribute('href') for link in header]\n",
    "\n",
    "# 4.4 - Get Texts for each finding\n",
    "list_description = [des.text for des in description]\n",
    "print('Header',len(list_header), 'Publish',len(list_publish), 'Company',len(list_company[1:]), 'Ort',len(list_ort), 'Desc', len(list_description), 'Link',len(list_link))\n",
    "\n",
    "# 4.5 - Total Search Page Number\n",
    "list_result = [res.text for res in result]\n",
    "number_of_page = int(list_result[-2])\n",
    "print(f'Number of Jobs Pages = {number_of_page}')\n",
    "\n",
    "# 4.6 - DataFrame df\n",
    "d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company=np.array(list_company[1:]), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "df = pd.DataFrame.from_dict(d, orient='index')\n",
    "df = df.T\n",
    "\n",
    "\n",
    "# 4.7 Repeat Process for every Web Page\n",
    "while  page_number < number_of_page:\n",
    "    page_number+=1\n",
    "    \n",
    "    # 4.7.1 - Go to another page\n",
    "    link = f'https://www.stepstone.de/jobs/{job_link}/in-{ort_link}?radius={radius}&page={page_number}'\n",
    "    driver.get(link)\n",
    "    wait(10)\n",
    "    sleep(1.5)\n",
    "    \n",
    "    # 4.7.2 - Find the elements and get the Texts\n",
    "    list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O) \n",
    "    description = driver.find_elements(By.CLASS_NAME, 'resultlist-1pq4x2u')\n",
    "    list_description = [des.text for des in description]\n",
    "    header = driver.find_elements(By.CLASS_NAME, H)\n",
    "    list_link = [link.get_attribute('href') for link in header]\n",
    " \n",
    "    # 4.7.3 - Create new page Dataframe\n",
    "    d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company=np.array(list_company[1:]), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "    df2 = pd.DataFrame.from_dict(d, orient='index')\n",
    "    df2 = df2.T\n",
    "    \n",
    "    # 4.7.4 - Concatenate the DataFrames\n",
    "    df = pd.concat([df,df2], axis=0, ignore_index=True)\n",
    "    print(f'Page Number : {page_number}, DataFrame Shape : {df2.shape}')\n",
    "    \n",
    "\n",
    "# 5.1 - Save Data as csv \n",
    "print(f'DataFrame End : {df.shape}')\n",
    "df['website'] = website_name\n",
    "time_ = datetime.today().strftime('%Y-%m-%d')\n",
    "df['date'] = time_\n",
    "job_name2 = job_name.replace(' ', '_')\n",
    "df['search_title'] = job_name2\n",
    "\n",
    "path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/data'\n",
    "job_name3 = job_name.replace(' ', '-')\n",
    "time_ = datetime.today().strftime('%Y-%m-%d')\n",
    "df.to_csv(f'{path}/{job_name3}-{time_}.csv', index=False)\n",
    "\n",
    "# 6 - Quit\n",
    "end =datetime.now() \n",
    "print('Code Runned No Problem')\n",
    "print(f'Time = {end - start}')\n",
    "sleep(5)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bba6fe-9b6e-4110-8eb6-2c9444a77965",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 02 - JOBWARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74123825-811b-4b9e-b02f-1d35ac17737b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- Jobware Job Searching Selenium Project ----------------------\n",
      "Header 11 Publish 11 Company 11 Ort 11 Desc 11 Link 11\n",
      "['11 Treffer\\nSortierung: Relevanz - Datum']\n",
      "DataFrame End : (11, 6)\n",
      "Code Runned No Problem\n",
      "Time = 0:00:12.065372\n"
     ]
    }
   ],
   "source": [
    "print('---------------------- Jobware Job Searching Selenium Project ----------------------')\n",
    "\n",
    "start=datetime.now()  \n",
    "# 0 Link Descriptions\n",
    "link_original = 'https://www.jobware.de/jobsuche?jw_jobname=data%20analyst&jw_jobort=333**%20Rietberg&jw_ort_distance=50'\n",
    "\n",
    "website_name = 'jobware'\n",
    "radius = 50\n",
    "page_number = 0\n",
    "\n",
    "#  1 - Create Driver\n",
    "Path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/chromedriver'\n",
    "driver = webdriver.Chrome(Path)\n",
    "\n",
    "#  2 - Go to Website\n",
    "job_link = job_name.replace(' ', '%20').lower()\n",
    "ort_link = ort_.capitalize()\n",
    "link = f'https://www.jobware.de/jobsuche?jw_jobname={job_link}&jw_jobort=333**%20{ort_}&jw_ort_distance={radius}'\n",
    "\n",
    "driver.get(link)\n",
    "wait(10)\n",
    "sleep(2)\n",
    "\n",
    "#  3 - ActionChain Object created\n",
    "# 3.1 - Click Banned Accept\n",
    "actions = ActionChains(driver)\n",
    "akzeptieren = driver.find_element(By.XPATH, '/html/body/div[1]/div/div[3]/div[2]/button')\n",
    "actions.click(akzeptieren).perform()\n",
    "wait(10)\n",
    "sleep(0.5)\n",
    "\n",
    "\n",
    "# 4 -  Take Infos from Page\n",
    "# 4.1 - Headers, Company, City, Description\n",
    "H, P, C, O = 'h2', 'date', 'company', 'location'\n",
    "list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O)\n",
    "description = driver.find_elements(By.CLASS_NAME, 'task')\n",
    "list_description = [des.text for des in description]\n",
    "\n",
    "links = driver.find_elements(By.CLASS_NAME, 'job')\n",
    "list_link = [link.get_attribute('href') for link in links]\n",
    "\n",
    "print('Header',len(list_header), 'Publish',len(list_publish), 'Company',len(list_company), 'Ort',len(list_ort), 'Desc', len(list_description), 'Link',len(list_link))\n",
    "\n",
    "# 4.2 - Total Search Page Number\n",
    "result = driver.find_elements(By.CLASS_NAME, 'result-sort')\n",
    "list_result = [res.text for res in result]\n",
    "print(list_result)\n",
    "\n",
    "# 4.3 - DataFrame df\n",
    "d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company=np.array(list_company), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "df = pd.DataFrame.from_dict(d, orient='index')\n",
    "df = df.T\n",
    "\n",
    "# 5.1 - Save Data as csv\n",
    "print(f'DataFrame End : {df.shape}')\n",
    "df['website'] = website_name\n",
    "time_ = datetime.today().strftime('%Y-%m-%d')\n",
    "df['date'] = time_\n",
    "job_name2 = job_name.replace(' ', '_')\n",
    "df['search_title'] = job_name2\n",
    "\n",
    "\n",
    "\n",
    "df.to_csv(f'{path}/{job_name3}-{time_}.csv', mode='a', index=False, header=False)\n",
    "\n",
    "# 6.1 Quit\n",
    "end =datetime.now() \n",
    "print('Code Runned No Problem')\n",
    "print(f'Time = {end - start}')\n",
    "sleep(5)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abde48a-5765-4f02-81fd-b32ce46555e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 03 - LINKEDIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dbf2fbe-1a18-43d0-b510-6c6015993c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- Linkedin Job Searching Selenium Project ----------------------\n",
      "Header 37 Publish 36 Company 35 Ort 37 Desc 11 Link 35\n",
      "Number of Jobs Pages = ['Rietberg, Kuzey Ren-Vestfalya, Almanya konumunda 37 Business Analyst iş ilanı (1 yeni)']\n",
      "DataFrame End : (37, 9)\n",
      "Code Runned No Problem\n",
      "Time = 0:00:38.964703\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>publish</th>\n",
       "      <th>company</th>\n",
       "      <th>city</th>\n",
       "      <th>description</th>\n",
       "      <th>link</th>\n",
       "      <th>website</th>\n",
       "      <th>date</th>\n",
       "      <th>search_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Analyst (M/W/D)</td>\n",
       "      <td>4 gün önce</td>\n",
       "      <td>Positive Thinking Company</td>\n",
       "      <td>Bielefeld</td>\n",
       "      <td>None</td>\n",
       "      <td>https://de.linkedin.com/jobs/view/business-ana...</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>2022-11-19</td>\n",
       "      <td>Business_Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business Analyst agree21 , Junior oder Profi (...</td>\n",
       "      <td>4 gün önce</td>\n",
       "      <td>Beckmann &amp; Partner CONSULT</td>\n",
       "      <td>Bielefeld</td>\n",
       "      <td>None</td>\n",
       "      <td>https://de.linkedin.com/jobs/view/business-ana...</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>2022-11-19</td>\n",
       "      <td>Business_Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Product Owner / Business Analyst (m/w/d) I E-C...</td>\n",
       "      <td>1 ay önce</td>\n",
       "      <td>Arvato Systems</td>\n",
       "      <td>Bielefeld</td>\n",
       "      <td>None</td>\n",
       "      <td>https://de.linkedin.com/jobs/view/product-owne...</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>2022-11-19</td>\n",
       "      <td>Business_Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Solution Analyst (m/f/d)</td>\n",
       "      <td>4 gün önce</td>\n",
       "      <td>Infopulse</td>\n",
       "      <td>Bielefeld</td>\n",
       "      <td>None</td>\n",
       "      <td>https://de.linkedin.com/jobs/view/business-sol...</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>2022-11-19</td>\n",
       "      <td>Business_Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Analyst (m/w/d) Production</td>\n",
       "      <td>4 hafta önce</td>\n",
       "      <td>GOLDBECK</td>\n",
       "      <td>Bielefeld</td>\n",
       "      <td>None</td>\n",
       "      <td>https://de.linkedin.com/jobs/view/business-ana...</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>2022-11-19</td>\n",
       "      <td>Business_Analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title       publish  \\\n",
       "0                           Business Analyst (M/W/D)    4 gün önce   \n",
       "1  Business Analyst agree21 , Junior oder Profi (...    4 gün önce   \n",
       "2  Product Owner / Business Analyst (m/w/d) I E-C...     1 ay önce   \n",
       "3                  Business Solution Analyst (m/f/d)    4 gün önce   \n",
       "4                Business Analyst (m/w/d) Production  4 hafta önce   \n",
       "\n",
       "                      company       city description  \\\n",
       "0   Positive Thinking Company  Bielefeld        None   \n",
       "1  Beckmann & Partner CONSULT  Bielefeld        None   \n",
       "2              Arvato Systems  Bielefeld        None   \n",
       "3                   Infopulse  Bielefeld        None   \n",
       "4                    GOLDBECK  Bielefeld        None   \n",
       "\n",
       "                                                link   website        date  \\\n",
       "0  https://de.linkedin.com/jobs/view/business-ana...  linkedin  2022-11-19   \n",
       "1  https://de.linkedin.com/jobs/view/business-ana...  linkedin  2022-11-19   \n",
       "2  https://de.linkedin.com/jobs/view/product-owne...  linkedin  2022-11-19   \n",
       "3  https://de.linkedin.com/jobs/view/business-sol...  linkedin  2022-11-19   \n",
       "4  https://de.linkedin.com/jobs/view/business-ana...  linkedin  2022-11-19   \n",
       "\n",
       "       search_title  \n",
       "0  Business_Analyst  \n",
       "1  Business_Analyst  \n",
       "2  Business_Analyst  \n",
       "3  Business_Analyst  \n",
       "4  Business_Analyst  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('---------------------- Linkedin Job Searching Selenium Project ----------------------')\n",
    "   \n",
    "\n",
    "start=datetime.now()  \n",
    "# 0 Link Descriptions\n",
    "link_original = 'https://www.linkedin.com/jobs/search/?currentJobId=3199974140&distance=25&keywords=data%20analyst&location=Rietberg' \n",
    "\n",
    "website_name =  'linkedin'\n",
    "radius = 40\n",
    "page_number = 1\n",
    "\n",
    "#  1 - Create Driver\n",
    "Path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/chromedriver'\n",
    "driver = webdriver.Chrome(Path)\n",
    "\n",
    "#  2 - Go to Website\n",
    "job_link = job_name.replace(' ', '%20').lower()\n",
    "\n",
    "link2 = f'https://www.linkedin.com/jobs/search/?distance=25&keywords={job_link}&location={ort_}'\n",
    "driver.get(link2)\n",
    "wait(10)\n",
    "sleep(2)\n",
    "\n",
    "#  3 - ActionChain Object created\n",
    "# 3.1 - Click Banned Accept\n",
    "actions = ActionChains(driver)\n",
    "akzeptieren = driver.find_element(By.TAG_NAME, 'button')\n",
    "actions.click(akzeptieren).perform()\n",
    "wait(10)\n",
    "sleep(0.5)\n",
    "\n",
    "# 3.2 - Scroll Down Function\n",
    "scroll_down(4)\n",
    "\n",
    "# 4 -  Take Infos from Page\n",
    "# 4.1 - Headers, Company, City, Description\n",
    "H, P, C, O = 'base-search-card__title', 'job-search-card__listdate', 'hidden-nested-link', 'job-search-card__location'\n",
    "list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O)\n",
    "\n",
    "# 4.2 - Link Lists\n",
    "links = driver.find_elements(By.CLASS_NAME, 'base-card__full-link')\n",
    "list_link = [link.get_attribute('href') for link in links]\n",
    "\n",
    "print('Header',len(list_header), 'Publish',len(list_publish), 'Company',len(list_company), 'Ort',len(list_ort), 'Desc', len(list_description), 'Link',len(list_link))\n",
    "\n",
    "# 4.3 - Total Search Page Number\n",
    "result = driver.find_elements(By.CLASS_NAME, 'results-context-header__context')\n",
    "list_result = [res.text for res in result]\n",
    "print(f'Number of Jobs Pages = {list_result}')\n",
    "\n",
    "\n",
    "# 4.4 - DataFrame df\n",
    "d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company=np.array(list_company), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "df = pd.DataFrame.from_dict(d, orient='index')\n",
    "df = df.T\n",
    "df['description'] = None\n",
    "df['website'] = website_name\n",
    "df['date'] = time_\n",
    "job_name2 = job_name.replace(' ', '_')\n",
    "df['search_title'] = job_name2\n",
    "\n",
    "# 5.1 - Save Data as csv \n",
    "print(f'DataFrame End : {df.shape}')\n",
    "df.loc[df.website =='linkedin', 'city'] = df.loc[df.website =='linkedin', 'city'].str.replace(', Kuzey Ren-Vestfalya, Almanya', '')\n",
    "df.to_csv(f'{path}/{job_name3}-{time_}.csv', mode='a', index=False, header=False)\n",
    "\n",
    "# 4.5 Quit\n",
    "end =datetime.now() \n",
    "print('Code Runned No Problem')\n",
    "print(f'Time = {end - start}')\n",
    "sleep(5)\n",
    "driver.quit()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed69c2b-d83a-44d8-88d8-a8268a0f64a5",
   "metadata": {},
   "source": [
    "# Stepstone, Jobware and Linkedin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41d6a02e-7230-4c2a-958d-18e2f26459cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- StepStone Job Searching Selenium Project ----------------------\n",
      "1 Business Analyst\n",
      "Header 25 Publish 25 Company 25 Ort 25 Desc 25 Link 25\n",
      "Number of Jobs Pages = 3\n",
      "Page Number : 2, DataFrame Shape : (25, 6)\n",
      "Page Number : 3, DataFrame Shape : (3, 6)\n",
      "DataFrame End : (53, 6)\n",
      "Code Runned No Problem\n",
      "Time = 0:01:03.743592\n",
      "---------------------- Jobware Job Searching Selenium Project ----------------------\n",
      "Header 11 Publish 11 Company 11 Ort 11 Desc 11 Link 11\n",
      "['11 Treffer\\nSortierung: Relevanz - Datum']\n",
      "DataFrame End : (11, 6)\n",
      "Code Runned No Problem\n",
      "Time = 0:00:22.101311\n",
      "---------------------- Linkedin Job Searching Selenium Project ----------------------\n",
      "Header 37 Publish 36 Company 35 Ort 37 Desc 11 Link 35\n",
      "Number of Jobs Pages = ['Rietberg, Kuzey Ren-Vestfalya, Almanya konumunda 37 Business Analyst iş ilanı (1 yeni)']\n",
      "DataFrame End : (37, 9)\n",
      "Code Runned No Problem\n",
      "Time = 0:00:42.961378\n",
      "---------------------- StepStone Job Searching Selenium Project ----------------------\n",
      "2 Data Scientist\n",
      "Header 25 Publish 25 Company 25 Ort 25 Desc 25 Link 25\n",
      "Number of Jobs Pages = 2\n",
      "Page Number : 2, DataFrame Shape : (2, 6)\n",
      "DataFrame End : (27, 6)\n",
      "Code Runned No Problem\n",
      "Time = 0:00:49.887598\n",
      "---------------------- Jobware Job Searching Selenium Project ----------------------\n",
      "Header 14 Publish 14 Company 14 Ort 14 Desc 13 Link 14\n",
      "['8 Treffer\\nSortierung: Relevanz - Datum']\n",
      "DataFrame End : (14, 6)\n",
      "Code Runned No Problem\n",
      "Time = 0:00:20.695229\n",
      "---------------------- Linkedin Job Searching Selenium Project ----------------------\n",
      "Header 150 Publish 149 Company 145 Ort 150 Desc 13 Link 145\n",
      "Number of Jobs Pages = ['Rietberg, Kuzey Ren-Vestfalya, Almanya konumunda 874 Data Scientist iş ilanı (29 yeni)']\n",
      "DataFrame End : (150, 9)\n",
      "Code Runned No Problem\n",
      "Time = 0:00:56.900517\n",
      "---------------------- StepStone Job Searching Selenium Project ----------------------\n",
      "3 Data Analyst\n",
      "Header 25 Publish 25 Company 25 Ort 25 Desc 25 Link 25\n",
      "Number of Jobs Pages = 21\n",
      "Page Number : 2, DataFrame Shape : (25, 6)\n",
      "Page Number : 3, DataFrame Shape : (25, 6)\n",
      "Page Number : 4, DataFrame Shape : (25, 6)\n",
      "Page Number : 5, DataFrame Shape : (25, 6)\n",
      "Page Number : 6, DataFrame Shape : (25, 6)\n",
      "Page Number : 7, DataFrame Shape : (25, 6)\n",
      "Page Number : 8, DataFrame Shape : (25, 6)\n",
      "Page Number : 9, DataFrame Shape : (25, 6)\n",
      "Page Number : 10, DataFrame Shape : (25, 6)\n",
      "Page Number : 11, DataFrame Shape : (25, 6)\n",
      "Page Number : 12, DataFrame Shape : (25, 6)\n",
      "Page Number : 13, DataFrame Shape : (25, 6)\n",
      "Page Number : 14, DataFrame Shape : (25, 6)\n",
      "Page Number : 15, DataFrame Shape : (25, 6)\n",
      "Page Number : 16, DataFrame Shape : (25, 6)\n",
      "Page Number : 17, DataFrame Shape : (25, 6)\n",
      "Page Number : 18, DataFrame Shape : (25, 6)\n",
      "Page Number : 19, DataFrame Shape : (25, 6)\n",
      "Page Number : 20, DataFrame Shape : (25, 6)\n",
      "Page Number : 21, DataFrame Shape : (10, 6)\n",
      "DataFrame End : (510, 6)\n",
      "Code Runned No Problem\n",
      "Time = 0:08:19.539451\n",
      "---------------------- Jobware Job Searching Selenium Project ----------------------\n",
      "Header 14 Publish 14 Company 14 Ort 14 Desc 13 Link 14\n",
      "['14 Treffer\\nSortierung: Relevanz - Datum']\n",
      "DataFrame End : (14, 6)\n",
      "Code Runned No Problem\n",
      "Time = 0:00:12.336059\n",
      "---------------------- Linkedin Job Searching Selenium Project ----------------------\n",
      "Header 150 Publish 148 Company 136 Ort 150 Desc 13 Link 136\n",
      "Number of Jobs Pages = ['Rietberg, Kuzey Ren-Vestfalya, Almanya konumunda 890 Data Analyst iş ilanı (28 yeni)']\n",
      "DataFrame End : (150, 9)\n",
      "Code Runned No Problem\n",
      "Time = 0:00:47.210362\n",
      "Total Time: 0:14:23.381916\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Title : Web Scrapping by Selenium \n",
    "Project Purpose: From StepStone scrap data for some Job Titels\n",
    "1 - Create Driver\n",
    "2 - Go to Website\n",
    "3 - Create ActionChain Object\n",
    "    3.1 - Click Banned \n",
    "4 - Take Title and Infos from Page\n",
    "    4.1 - Create Lists \n",
    "    4.2 - Create DataFrame\n",
    "    4.3 - Repeat Process\n",
    "    4.4 - Print and Save DataFrame\n",
    "'''\n",
    "\n",
    "job_list = ['Business Analyst', 'Data Scientist', 'Data Analyst' ]\n",
    "n=0\n",
    "start_01=datetime.now()\n",
    "while n<len(job_list):\n",
    "    print('---------------------- StepStone Job Searching Selenium Project ----------------------')\n",
    "    start=datetime.now()  \n",
    "    n+=1\n",
    "    # Link Descriptions\n",
    "    link_original_stepstone = 'https://www.stepstone.de/jobs/data-analyst/in-rietberg?radius=50&page=2'\n",
    "\n",
    "    website_name = 'stepstone'\n",
    "    job_name = job_list[n-1] \n",
    "    print(n, job_name)\n",
    "    ort_ = 'Rietberg'\n",
    "    radius = 50\n",
    "    page_number = 1\n",
    "\n",
    "    #  1 - Create Driver\n",
    "    Path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/chromedriver'\n",
    "    driver = webdriver.Chrome(Path)\n",
    "\n",
    "    #  2 - Go to Website\n",
    "    job_link = job_name.replace(' ', '-').lower()\n",
    "    ort_link = ort_.lower()\n",
    "    link = f'https://www.stepstone.de/jobs/{job_link}/in-{ort_link}?radius={radius}&page={page_number}'\n",
    "\n",
    "    driver.get(link)\n",
    "    wait(10)\n",
    "    sleep(2)\n",
    "\n",
    "    #  3 - ActionChain Object created\n",
    "    # 3.1 - Click Banned Accept\n",
    "    ID = 'ccmgt_explicit_accept'\n",
    "    click_bann_byID(ID)\n",
    "\n",
    "\n",
    "    # 4 -  Take Infos from Page\n",
    "    # 4.1 - Headers, Publish_Time ,Company, City\n",
    "    H, P, C, O = 'resultlist-1uvdp0v', 'resultlist-w7zbt7', 'resultlist-1va1dj8', 'resultlist-suri3e'\n",
    "    list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O)\n",
    "\n",
    "    # 4.2 - Description and Page number of results\n",
    "    description = driver.find_elements(By.CLASS_NAME, 'resultlist-1fp8oay')\n",
    "    result = driver.find_elements(By.CLASS_NAME, 'resultlist-1jx3vjx')\n",
    "\n",
    "\n",
    "    # 4.3 - Get Links\n",
    "    header = driver.find_elements(By.CLASS_NAME, H)\n",
    "    list_link = [link.get_attribute('href') for link in header]\n",
    "\n",
    "    # 4.4 - Get Texts for each finding\n",
    "    list_description = [des.text for des in description]\n",
    "    print('Header',len(list_header), 'Publish',len(list_publish), 'Company',len(list_company[1:]), 'Ort',len(list_ort), 'Desc', len(list_description), 'Link',len(list_link))\n",
    "\n",
    "    # 4.5 - Total Search Page Number\n",
    "    list_result = [res.text for res in result]\n",
    "    number_of_page = int(list_result[-2])\n",
    "    print(f'Number of Jobs Pages = {number_of_page}')\n",
    "\n",
    "    # 4.6 - DataFrame df\n",
    "    d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company=np.array(list_company[1:]), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "    df = pd.DataFrame.from_dict(d, orient='index')\n",
    "    df = df.T\n",
    "\n",
    "\n",
    "    # 4.7 Repeat Process for every Web Page\n",
    "    while  page_number < number_of_page:\n",
    "        page_number+=1\n",
    "\n",
    "        # 4.7.1 - Go to another page\n",
    "        link = f'https://www.stepstone.de/jobs/{job_link}/in-{ort_link}?radius={radius}&page={page_number}'\n",
    "        driver.get(link)\n",
    "        wait(10)\n",
    "        sleep(1.5)\n",
    "\n",
    "        # 4.7.2 - Find the elements and get the Texts\n",
    "        list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O) \n",
    "        description = driver.find_elements(By.CLASS_NAME, 'resultlist-1pq4x2u')\n",
    "        list_description = [des.text for des in description]\n",
    "        header = driver.find_elements(By.CLASS_NAME, H)\n",
    "        list_link = [link.get_attribute('href') for link in header]\n",
    "\n",
    "        # 4.7.3 - Create new page Dataframe\n",
    "        d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company=np.array(list_company[1:]), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "        df2 = pd.DataFrame.from_dict(d, orient='index')\n",
    "        df2 = df2.T\n",
    "\n",
    "        # 4.7.4 - Concatenate the DataFrames\n",
    "        df = pd.concat([df,df2], axis=0, ignore_index=True)\n",
    "        print(f'Page Number : {page_number}, DataFrame Shape : {df2.shape}')\n",
    "\n",
    "\n",
    "    # 5.1 - Save Data as csv \n",
    "    print(f'DataFrame End : {df.shape}')\n",
    "    df['website'] = website_name\n",
    "    time_ = datetime.today().strftime('%Y-%m-%d')\n",
    "    df['date'] = time_\n",
    "    job_name2 = job_name.replace(' ', '_')\n",
    "    df['search_title'] = job_name2\n",
    "\n",
    "    path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/data'\n",
    "    job_name3 = job_name.replace(' ', '-')\n",
    "    time_ = datetime.today().strftime('%Y-%m-%d')\n",
    "    df.to_csv(f'{path}/{job_name3}-{time_}.csv', index=False)\n",
    "\n",
    "    # 6 - Quit\n",
    "    end =datetime.now() \n",
    "    print('Code Runned No Problem')\n",
    "    print(f'Time = {end - start}')\n",
    "    sleep(5)\n",
    "    driver.quit()\n",
    "\n",
    "    print('---------------------- Jobware Job Searching Selenium Project ----------------------')\n",
    "\n",
    "    start=datetime.now()  \n",
    "    # 0 Link Descriptions\n",
    "    link_original = 'https://www.jobware.de/jobsuche?jw_jobname=data%20analyst&jw_jobort=333**%20Rietberg&jw_ort_distance=50'\n",
    "\n",
    "    website_name = 'jobware'\n",
    "    radius = 50\n",
    "    page_number = 0\n",
    "\n",
    "    #  1 - Create Driver\n",
    "    Path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/chromedriver'\n",
    "    driver = webdriver.Chrome(Path)\n",
    "\n",
    "    #  2 - Go to Website\n",
    "    job_link = job_name.replace(' ', '%20').lower()\n",
    "    ort_link = ort_.capitalize()\n",
    "    link = f'https://www.jobware.de/jobsuche?jw_jobname={job_link}&jw_jobort=333**%20{ort_}&jw_ort_distance={radius}'\n",
    "\n",
    "    driver.get(link)\n",
    "    wait(10)\n",
    "    sleep(2)\n",
    "\n",
    "    #  3 - ActionChain Object created\n",
    "    # 3.1 - Click Banned Accept\n",
    "    actions = ActionChains(driver)\n",
    "    akzeptieren = driver.find_element(By.XPATH, '/html/body/div[1]/div/div[3]/div[2]/button')\n",
    "    actions.click(akzeptieren).perform()\n",
    "    wait(10)\n",
    "    sleep(0.5)\n",
    "\n",
    "\n",
    "    # 4 -  Take Infos from Page\n",
    "    # 4.1 - Headers, Company, City, Description\n",
    "    H, P, C, O = 'h2', 'date', 'company', 'location'\n",
    "    list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O)\n",
    "    description = driver.find_elements(By.CLASS_NAME, 'task')\n",
    "    list_description = [des.text for des in description]\n",
    "\n",
    "    links = driver.find_elements(By.CLASS_NAME, 'job')\n",
    "    list_link = [link.get_attribute('href') for link in links]\n",
    "\n",
    "    print('Header',len(list_header), 'Publish',len(list_publish), 'Company',len(list_company), 'Ort',len(list_ort), 'Desc', len(list_description), 'Link',len(list_link))\n",
    "\n",
    "    # 4.2 - Total Search Page Number\n",
    "    result = driver.find_elements(By.CLASS_NAME, 'result-sort')\n",
    "    list_result = [res.text for res in result]\n",
    "    print(list_result)\n",
    "\n",
    "    # 4.3 - DataFrame df\n",
    "    d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company=np.array(list_company), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "    df = pd.DataFrame.from_dict(d, orient='index')\n",
    "    df = df.T\n",
    "\n",
    "    # 5.1 - Save Data as csv\n",
    "    print(f'DataFrame End : {df.shape}')\n",
    "    df['website'] = website_name\n",
    "    time_ = datetime.today().strftime('%Y-%m-%d')\n",
    "    df['date'] = time_\n",
    "    job_name2 = job_name.replace(' ', '_')\n",
    "    df['search_title'] = job_name2\n",
    "\n",
    "\n",
    "\n",
    "    df.to_csv(f'{path}/{job_name3}-{time_}.csv', mode='a', index=False, header=False)\n",
    "\n",
    "    # 6.1 Quit\n",
    "    end =datetime.now() \n",
    "    print('Code Runned No Problem')\n",
    "    print(f'Time = {end - start}')\n",
    "    sleep(5)\n",
    "    driver.quit()\n",
    "\n",
    "    print('---------------------- Linkedin Job Searching Selenium Project ----------------------')\n",
    "\n",
    "\n",
    "    start=datetime.now()  \n",
    "    # 0 Link Descriptions\n",
    "    link_original = 'https://www.linkedin.com/jobs/search/?currentJobId=3199974140&distance=25&keywords=data%20analyst&location=Rietberg' \n",
    "\n",
    "    website_name =  'linkedin'\n",
    "    radius = 40\n",
    "    page_number = 1\n",
    "\n",
    "    #  1 - Create Driver\n",
    "    Path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/chromedriver'\n",
    "    driver = webdriver.Chrome(Path)\n",
    "\n",
    "    #  2 - Go to Website\n",
    "    job_link = job_name.replace(' ', '%20').lower()\n",
    "\n",
    "    link2 = f'https://www.linkedin.com/jobs/search/?distance=25&keywords={job_link}&location={ort_}'\n",
    "    driver.get(link2)\n",
    "    wait(10)\n",
    "    sleep(2)\n",
    "\n",
    "    #  3 - ActionChain Object created\n",
    "    # 3.1 - Click Banned Accept\n",
    "    actions = ActionChains(driver)\n",
    "    akzeptieren = driver.find_element(By.TAG_NAME, 'button')\n",
    "    actions.click(akzeptieren).perform()\n",
    "    wait(10)\n",
    "    sleep(0.5)\n",
    "\n",
    "    # 3.2 - Scroll Down Function\n",
    "    scroll_down(4)\n",
    "\n",
    "    # 4 -  Take Infos from Page\n",
    "    # 4.1 - Headers, Company, City, Description\n",
    "    H, P, C, O = 'base-search-card__title', 'job-search-card__listdate', 'hidden-nested-link', 'job-search-card__location'\n",
    "    list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O)\n",
    "\n",
    "    # 4.2 - Link Lists\n",
    "    links = driver.find_elements(By.CLASS_NAME, 'base-card__full-link')\n",
    "    list_link = [link.get_attribute('href') for link in links]\n",
    "\n",
    "    print('Header',len(list_header), 'Publish',len(list_publish), 'Company',len(list_company), 'Ort',len(list_ort), 'Desc', len(list_description), 'Link',len(list_link))\n",
    "\n",
    "    # 4.3 - Total Search Page Number\n",
    "    result = driver.find_elements(By.CLASS_NAME, 'results-context-header__context')\n",
    "    list_result = [res.text for res in result]\n",
    "    print(f'Number of Jobs Pages = {list_result}')\n",
    "\n",
    "\n",
    "    # 4.4 - DataFrame df\n",
    "    d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company=np.array(list_company), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "    df = pd.DataFrame.from_dict(d, orient='index')\n",
    "    df = df.T\n",
    "    df['description'] = None\n",
    "    df['website'] = website_name\n",
    "    df['date'] = time_\n",
    "    job_name2 = job_name.replace(' ', '_')\n",
    "    df['search_title'] = job_name2\n",
    "\n",
    "    # 5.1 - Save Data as csv \n",
    "    print(f'DataFrame End : {df.shape}')\n",
    "    df.loc[df.website =='linkedin', 'city'] = df.loc[df.website =='linkedin', 'city'].str.replace(', Kuzey Ren-Vestfalya, Almanya', '')\n",
    "    df.to_csv(f'{path}/{job_name3}-{time_}.csv', mode='a', index=False, header=False)\n",
    "\n",
    "    # 4.5 Quit\n",
    "    end =datetime.now() \n",
    "    print('Code Runned No Problem')\n",
    "    print(f'Time = {end - start}')\n",
    "    sleep(5)\n",
    "    driver.quit()\n",
    "\n",
    "    df.head()\n",
    "    \n",
    "end_01 =datetime.now()\n",
    "print(f'Total Time: {end_01 - start_01}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed0c7c7-9ab7-485e-a134-141bccf0155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "675b907e-82b6-40b7-97c7-77d15d98089e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Business Analyst\n",
      "2\n",
      "Data Scientist\n",
      "3\n",
      "Data Analyst\n"
     ]
    }
   ],
   "source": [
    "job_list = ['Business Analyst', 'Data Scientist', 'Data Analyst' ]\n",
    "n=0\n",
    "\n",
    "while n<3:\n",
    "    n+=1\n",
    "    job_name = job_list[n-1]\n",
    "    print(n)\n",
    "    print(job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e007d99b-d2d7-4cdc-a2ed-57c810fdb2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9dd81a-2d93-4d02-a614-1d4dedd2582c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
